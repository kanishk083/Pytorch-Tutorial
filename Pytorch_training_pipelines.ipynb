{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-pVtHliV7ZfX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "cECSw3EF77lM",
        "outputId": "b3dd12b1-fcff-4b03-fa45-5edb3fed1f20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-449903a1-810f-4782-9907-c30d8b641935\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-449903a1-810f-4782-9907-c30d8b641935')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-449903a1-810f-4782-9907-c30d8b641935 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-449903a1-810f-4782-9907-c30d8b641935');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a7d95abb-6dcf-4150-aac5-d5d0e40b610d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7d95abb-6dcf-4150-aac5-d5d0e40b610d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a7d95abb-6dcf-4150-aac5-d5d0e40b610d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K82D69Vf8LOS",
        "outputId": "a4e39a61-5dd0-4902-e83e-0add5f4b082d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['id','Unnamed: 32'], inplace=True)"
      ],
      "metadata": {
        "id": "cfTpIdcG8OAD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "2aTNkNzs8al1",
        "outputId": "285c7a6b-8b33-4356-b99a-7cea81e8b562"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        17.99         10.38          122.80     1001.0   \n",
              "1         M        20.57         17.77          132.90     1326.0   \n",
              "2         M        19.69         21.25          130.00     1203.0   \n",
              "3         M        11.42         20.38           77.58      386.1   \n",
              "4         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.2419  ...         25.38          17.33           184.60   \n",
              "1         0.1812  ...         24.99          23.41           158.80   \n",
              "2         0.2069  ...         23.57          25.53           152.50   \n",
              "3         0.2597  ...         14.91          26.50            98.87   \n",
              "4         0.1809  ...         22.54          16.67           152.20   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9d07ce9-910f-4514-ba66-b7609a5724a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9d07ce9-910f-4514-ba66-b7609a5724a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9d07ce9-910f-4514-ba66-b7609a5724a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9d07ce9-910f-4514-ba66-b7609a5724a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e4122562-48d6-4fef-8972-31c9c56e9d59\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4122562-48d6-4fef-8972-31c9c56e9d59')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e4122562-48d6-4fef-8972-31c9c56e9d59 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split"
      ],
      "metadata": {
        "id": "7FEZIU148dr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,1:]\n",
        "y=df.iloc[:,0]"
      ],
      "metadata": {
        "id": "ccpC08AI8cnl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.2)"
      ],
      "metadata": {
        "id": "Va2ANJsL8y_p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scaling"
      ],
      "metadata": {
        "id": "BIHGWdrQ9DwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "qZJpmq-o9GOU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCf7kt9c9cJB",
        "outputId": "32f5cba5-bd82-4784-ad8f-03be0fe639dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.32632413,  2.39726682,  0.23688721, ..., -0.68145399,\n",
              "         0.60652635, -1.22483853],\n",
              "       [-0.81504648,  0.72904209, -0.80582324, ..., -0.70583665,\n",
              "         0.49826057, -0.18895589],\n",
              "       [ 0.31776385,  0.63397365,  0.25962673, ...,  0.63174815,\n",
              "        -0.33741598, -0.27717514],\n",
              "       ...,\n",
              "       [ 1.20803292, -0.07903963,  1.14605465, ...,  1.00200342,\n",
              "        -0.10565953, -0.09685277],\n",
              "       [ 2.63189276,  1.7544231 ,  2.58484623, ...,  2.23167236,\n",
              "         0.38661147,  0.16891465],\n",
              "       [ 1.89856214, -0.42309683,  1.81170248, ...,  1.50771794,\n",
              "        -0.31373283, -0.73103267]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "XQ5l7HqS9d5C",
        "outputId": "ecd86fb7-677f-4467-faaa-f3887dd0f6e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "414    M\n",
              "551    B\n",
              "54     M\n",
              "404    B\n",
              "292    B\n",
              "      ..\n",
              "506    B\n",
              "214    M\n",
              "317    M\n",
              "236    M\n",
              "373    M\n",
              "Name: diagnosis, Length: 455, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Label Encoding"
      ],
      "metadata": {
        "id": "sSZpztJa9gRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "VoSD5ih-9f2o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSLzrUX_9uz8",
        "outputId": "c4740c67-fa1c-4ae2-8daf-137e3b8647a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Numpy --> Pytorch"
      ],
      "metadata": {
        "id": "0okYzknZ9yBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train)\n",
        "X_test_tensor = torch.from_numpy(X_test)\n",
        "y_train_tensor = torch.from_numpy(y_train)\n",
        "y_test_tensor = torch.from_numpy(y_test)"
      ],
      "metadata": {
        "id": "OY7OhRKH93ks"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb16Un2a-Ydz",
        "outputId": "08ae276d-8293-4e7d-a16e-7755edbe8829"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCjgmzYC-m8f",
        "outputId": "ccdaddf1-a5f0-4898-f2cc-2788f7ea4db9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "9ch3-mCF-o31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN():\n",
        "\n",
        "  def __init__(self,X):\n",
        "    self.weights = torch.rand(X.shape[1],1,dtype=torch.float64,requires_grad=True)\n",
        "    self.bias = torch.zeros(1,dtype=torch.float64,requires_grad=True)\n",
        "\n",
        "  def forward(self,X):\n",
        "    #z=WX + b\n",
        "    z= torch.matmul(X,self.weights) + self.bias\n",
        "    y_pred = torch.sigmoid(z)\n",
        "    return y_pred\n",
        "\n",
        "  def loss_function(self, y_pred, y):\n",
        "    # Clamp predictions to avoid log(0)\n",
        "    epsilon = 1e-7\n",
        "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
        "\n",
        "    #calculation of loss function\n",
        "    loss = -(y_train_tensor * torch.log(y_pred) + (1 - y_train_tensor) * torch.log(1 - y_pred)).mean()\n",
        "    return loss\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ce_aQjfd-oDM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parameters"
      ],
      "metadata": {
        "id": "fmNaMc1UAJjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 1500"
      ],
      "metadata": {
        "id": "9vkf3ATpAJCV"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline Training"
      ],
      "metadata": {
        "id": "RXZ87gRQAS9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model creation\n",
        "model = SimpleNN(X_train_tensor)\n",
        "\n",
        "#looop\n",
        "for epoch in range(epochs):\n",
        "  #forwaed pass\n",
        "  y_pred = model.forward(X_train_tensor)\n",
        "\n",
        "  #loss calculation\n",
        "  loss = model.loss_function(y_pred,y_train_tensor)\n",
        "\n",
        "  #backward\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  with torch.no_grad():\n",
        "    model.weights -= learning_rate * model.weights.grad\n",
        "    model.bias -= learning_rate * model.bias.grad\n",
        "\n",
        "  #zero grad\n",
        "  model.weights.grad.zero_()\n",
        "  model.bias.grad.zero_()\n",
        "\n",
        "\n",
        "  #print each epoch in loop\n",
        "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbzJl8XUASS3",
        "outputId": "778eabf1-35f7-42f6-d95e-82461fc718b7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 4.035073702827832\n",
            "Epoch: 2, Loss: 3.94346410616698\n",
            "Epoch: 3, Loss: 3.8471500808106445\n",
            "Epoch: 4, Loss: 3.7439807447739883\n",
            "Epoch: 5, Loss: 3.630350497310871\n",
            "Epoch: 6, Loss: 3.5113995197058125\n",
            "Epoch: 7, Loss: 3.388999649365771\n",
            "Epoch: 8, Loss: 3.264942024613149\n",
            "Epoch: 9, Loss: 3.138041774654992\n",
            "Epoch: 10, Loss: 3.007357310350833\n",
            "Epoch: 11, Loss: 2.876262208767175\n",
            "Epoch: 12, Loss: 2.7436588618135525\n",
            "Epoch: 13, Loss: 2.605996419057084\n",
            "Epoch: 14, Loss: 2.456654954572247\n",
            "Epoch: 15, Loss: 2.308858138695398\n",
            "Epoch: 16, Loss: 2.163191134338149\n",
            "Epoch: 17, Loss: 2.0182068902634693\n",
            "Epoch: 18, Loss: 1.8779342726481145\n",
            "Epoch: 19, Loss: 1.7435661966892744\n",
            "Epoch: 20, Loss: 1.6172462637201042\n",
            "Epoch: 21, Loss: 1.4984831027595282\n",
            "Epoch: 22, Loss: 1.3906420190053779\n",
            "Epoch: 23, Loss: 1.2916364650803074\n",
            "Epoch: 24, Loss: 1.2054886040219677\n",
            "Epoch: 25, Loss: 1.1321066871207734\n",
            "Epoch: 26, Loss: 1.0709183410266232\n",
            "Epoch: 27, Loss: 1.020820204935463\n",
            "Epoch: 28, Loss: 0.9802186123926431\n",
            "Epoch: 29, Loss: 0.9472679127481227\n",
            "Epoch: 30, Loss: 0.9202115488461808\n",
            "Epoch: 31, Loss: 0.8976010996531659\n",
            "Epoch: 32, Loss: 0.8783400024259024\n",
            "Epoch: 33, Loss: 0.8616341844989712\n",
            "Epoch: 34, Loss: 0.8469194596690326\n",
            "Epoch: 35, Loss: 0.8337957542086369\n",
            "Epoch: 36, Loss: 0.8219763317358352\n",
            "Epoch: 37, Loss: 0.811251530146812\n",
            "Epoch: 38, Loss: 0.8014639634693896\n",
            "Epoch: 39, Loss: 0.7924919858135027\n",
            "Epoch: 40, Loss: 0.7842388126962749\n",
            "Epoch: 41, Loss: 0.7766253940948946\n",
            "Epoch: 42, Loss: 0.7695857225238312\n",
            "Epoch: 43, Loss: 0.7630636992391868\n",
            "Epoch: 44, Loss: 0.7570109901552541\n",
            "Epoch: 45, Loss: 0.7513855108496112\n",
            "Epoch: 46, Loss: 0.7461503157485856\n",
            "Epoch: 47, Loss: 0.7412727529271189\n",
            "Epoch: 48, Loss: 0.7367237996052192\n",
            "Epoch: 49, Loss: 0.732477526052271\n",
            "Epoch: 50, Loss: 0.7285106550936017\n",
            "Epoch: 51, Loss: 0.7248021958906722\n",
            "Epoch: 52, Loss: 0.7213331373926203\n",
            "Epoch: 53, Loss: 0.7180861908353238\n",
            "Epoch: 54, Loss: 0.715045573091084\n",
            "Epoch: 55, Loss: 0.7121968242407464\n",
            "Epoch: 56, Loss: 0.709526653839455\n",
            "Epoch: 57, Loss: 0.7070228111873899\n",
            "Epoch: 58, Loss: 0.7046739756065439\n",
            "Epoch: 59, Loss: 0.7024696633173634\n",
            "Epoch: 60, Loss: 0.7004001480297951\n",
            "Epoch: 61, Loss: 0.6984563928230498\n",
            "Epoch: 62, Loss: 0.6966299912924667\n",
            "Epoch: 63, Loss: 0.6949131162935303\n",
            "Epoch: 64, Loss: 0.6932984749155411\n",
            "Epoch: 65, Loss: 0.6917792685742452\n",
            "Epoch: 66, Loss: 0.6903491573280525\n",
            "Epoch: 67, Loss: 0.6890022277008068\n",
            "Epoch: 68, Loss: 0.6877329634400434\n",
            "Epoch: 69, Loss: 0.6865362187578168\n",
            "Epoch: 70, Loss: 0.6854071936958132\n",
            "Epoch: 71, Loss: 0.6843414113314888\n",
            "Epoch: 72, Loss: 0.6833346966008899\n",
            "Epoch: 73, Loss: 0.6823831565596726\n",
            "Epoch: 74, Loss: 0.6814831619392338\n",
            "Epoch: 75, Loss: 0.6806313298819681\n",
            "Epoch: 76, Loss: 0.6798245077602909\n",
            "Epoch: 77, Loss: 0.6790597579996619\n",
            "Epoch: 78, Loss: 0.6783343438376049\n",
            "Epoch: 79, Loss: 0.6776457159595619\n",
            "Epoch: 80, Loss: 0.6769914999590881\n",
            "Epoch: 81, Loss: 0.6763694845749597\n",
            "Epoch: 82, Loss: 0.675777610661647\n",
            "Epoch: 83, Loss: 0.6752139608526471\n",
            "Epoch: 84, Loss: 0.6746767498786204\n",
            "Epoch: 85, Loss: 0.6741643155042879\n",
            "Epoch: 86, Loss: 0.6736751100497972\n",
            "Epoch: 87, Loss: 0.6732076924638074\n",
            "Epoch: 88, Loss: 0.6727607209169635\n",
            "Epoch: 89, Loss: 0.6723329458857741\n",
            "Epoch: 90, Loss: 0.6719232036981913\n",
            "Epoch: 91, Loss: 0.6715304105134404\n",
            "Epoch: 92, Loss: 0.671153556709883\n",
            "Epoch: 93, Loss: 0.6707917016558942\n",
            "Epoch: 94, Loss: 0.6704439688399362\n",
            "Epoch: 95, Loss: 0.6701095413371683\n",
            "Epoch: 96, Loss: 0.6697876575910956\n",
            "Epoch: 97, Loss: 0.6694776074898714\n",
            "Epoch: 98, Loss: 0.6691787287179735\n",
            "Epoch: 99, Loss: 0.6688904033650404\n",
            "Epoch: 100, Loss: 0.6686120547746794\n",
            "Epoch: 101, Loss: 0.6683431446170717\n",
            "Epoch: 102, Loss: 0.6680831701701405\n",
            "Epoch: 103, Loss: 0.6678316617949908\n",
            "Epoch: 104, Loss: 0.6675881805921945\n",
            "Epoch: 105, Loss: 0.6673523162263465\n",
            "Epoch: 106, Loss: 0.6671236849071173\n",
            "Epoch: 107, Loss: 0.6669019275157831\n",
            "Epoch: 108, Loss: 0.6666867078669458\n",
            "Epoch: 109, Loss: 0.666477711095828\n",
            "Epoch: 110, Loss: 0.6662746421621774\n",
            "Epoch: 111, Loss: 0.6660772244624237\n",
            "Epoch: 112, Loss: 0.6658851985422957\n",
            "Epoch: 113, Loss: 0.665698320902653\n",
            "Epoch: 114, Loss: 0.6655163628917794\n",
            "Epoch: 115, Loss: 0.6653391096778681\n",
            "Epoch: 116, Loss: 0.6651663592958635\n",
            "Epoch: 117, Loss: 0.6649979217632396\n",
            "Epoch: 118, Loss: 0.6648336182596833\n",
            "Epoch: 119, Loss: 0.6646732803660099\n",
            "Epoch: 120, Loss: 0.6645167493579738\n",
            "Epoch: 121, Loss: 0.6643638755509489\n",
            "Epoch: 122, Loss: 0.664214517691754\n",
            "Epoch: 123, Loss: 0.6640685423941559\n",
            "Epoch: 124, Loss: 0.6639258236148465\n",
            "Epoch: 125, Loss: 0.6637862421669221\n",
            "Epoch: 126, Loss: 0.6636496852681087\n",
            "Epoch: 127, Loss: 0.6635160461211821\n",
            "Epoch: 128, Loss: 0.6633852235242179\n",
            "Epoch: 129, Loss: 0.6632571215084855\n",
            "Epoch: 130, Loss: 0.663131649001952\n",
            "Epoch: 131, Loss: 0.6630087195165253\n",
            "Epoch: 132, Loss: 0.6628882508572932\n",
            "Epoch: 133, Loss: 0.6627701648521493\n",
            "Epoch: 134, Loss: 0.6626543871003198\n",
            "Epoch: 135, Loss: 0.6625408467384017\n",
            "Epoch: 136, Loss: 0.6624294762226495\n",
            "Epoch: 137, Loss: 0.662320211126312\n",
            "Epoch: 138, Loss: 0.6622129899509368\n",
            "Epoch: 139, Loss: 0.6621077539506243\n",
            "Epoch: 140, Loss: 0.6620044469682909\n",
            "Epoch: 141, Loss: 0.6619030152830777\n",
            "Epoch: 142, Loss: 0.6618034074680968\n",
            "Epoch: 143, Loss: 0.6617055742577714\n",
            "Epoch: 144, Loss: 0.6616094684240815\n",
            "Epoch: 145, Loss: 0.6615150446610762\n",
            "Epoch: 146, Loss: 0.6614222594770591\n",
            "Epoch: 147, Loss: 0.6613310710939038\n",
            "Epoch: 148, Loss: 0.6612414393529876\n",
            "Epoch: 149, Loss: 0.6611533256272776\n",
            "Epoch: 150, Loss: 0.6610666927391301\n",
            "Epoch: 151, Loss: 0.6609815048834045\n",
            "Epoch: 152, Loss: 0.660897727555512\n",
            "Epoch: 153, Loss: 0.6608153274840611\n",
            "Epoch: 154, Loss: 0.66073427256777\n",
            "Epoch: 155, Loss: 0.6606545318163548\n",
            "Epoch: 156, Loss: 0.6605760752951154\n",
            "Epoch: 157, Loss: 0.6604988740729627\n",
            "Epoch: 158, Loss: 0.6604229001736507\n",
            "Epoch: 159, Loss: 0.6603481265299948\n",
            "Epoch: 160, Loss: 0.6602745269408679\n",
            "Epoch: 161, Loss: 0.6602020760307911\n",
            "Epoch: 162, Loss: 0.6601307492119377\n",
            "Epoch: 163, Loss: 0.6600605226483903\n",
            "Epoch: 164, Loss: 0.659991373222499\n",
            "Epoch: 165, Loss: 0.6599232785032006\n",
            "Epoch: 166, Loss: 0.6598562167161653\n",
            "Epoch: 167, Loss: 0.6597901667156558\n",
            "Epoch: 168, Loss: 0.6597251079579771\n",
            "Epoch: 169, Loss: 0.6596610204764223\n",
            "Epoch: 170, Loss: 0.6595978848576083\n",
            "Epoch: 171, Loss: 0.659535682219117\n",
            "Epoch: 172, Loss: 0.6594743941883541\n",
            "Epoch: 173, Loss: 0.6594140028825488\n",
            "Epoch: 174, Loss: 0.6593544908898222\n",
            "Epoch: 175, Loss: 0.6592958412512544\n",
            "Epoch: 176, Loss: 0.6592380374438892\n",
            "Epoch: 177, Loss: 0.6591810633646173\n",
            "Epoch: 178, Loss: 0.6591249033148822\n",
            "Epoch: 179, Loss: 0.6590695419861585\n",
            "Epoch: 180, Loss: 0.6590149644461567\n",
            "Epoch: 181, Loss: 0.6589611561257062\n",
            "Epoch: 182, Loss: 0.6589081028062794\n",
            "Epoch: 183, Loss: 0.6588557906081174\n",
            "Epoch: 184, Loss: 0.658804205978917\n",
            "Epoch: 185, Loss: 0.6587533356830548\n",
            "Epoch: 186, Loss: 0.6587031667913059\n",
            "Epoch: 187, Loss: 0.6586536866710373\n",
            "Epoch: 188, Loss: 0.658604882976843\n",
            "Epoch: 189, Loss: 0.6585567436415978\n",
            "Epoch: 190, Loss: 0.6585092568679061\n",
            "Epoch: 191, Loss: 0.6584624111199219\n",
            "Epoch: 192, Loss: 0.6584161951155192\n",
            "Epoch: 193, Loss: 0.6583705978187955\n",
            "Epoch: 194, Loss: 0.6583256084328888\n",
            "Epoch: 195, Loss: 0.6582812163930892\n",
            "Epoch: 196, Loss: 0.6582374113602321\n",
            "Epoch: 197, Loss: 0.6581941832143567\n",
            "Epoch: 198, Loss: 0.658151522048615\n",
            "Epoch: 199, Loss: 0.6581094181634195\n",
            "Epoch: 200, Loss: 0.6580678620608154\n",
            "Epoch: 201, Loss: 0.6580268444390686\n",
            "Epoch: 202, Loss: 0.6579863561874552\n",
            "Epoch: 203, Loss: 0.6579463883812449\n",
            "Epoch: 204, Loss: 0.6579069322768665\n",
            "Epoch: 205, Loss: 0.6578679793072494\n",
            "Epoch: 206, Loss: 0.6578295210773287\n",
            "Epoch: 207, Loss: 0.6577915493597103\n",
            "Epoch: 208, Loss: 0.6577540560904829\n",
            "Epoch: 209, Loss: 0.6577170333651768\n",
            "Epoch: 210, Loss: 0.6576804734348569\n",
            "Epoch: 211, Loss: 0.6576443687023457\n",
            "Epoch: 212, Loss: 0.6576087117185707\n",
            "Epoch: 213, Loss: 0.6575734951790322\n",
            "Epoch: 214, Loss: 0.6575387119203803\n",
            "Epoch: 215, Loss: 0.6575043549171047\n",
            "Epoch: 216, Loss: 0.6574704172783244\n",
            "Epoch: 217, Loss: 0.6574368922446793\n",
            "Epoch: 218, Loss: 0.6574037731853137\n",
            "Epoch: 219, Loss: 0.6573710535949538\n",
            "Epoch: 220, Loss: 0.6573387270910701\n",
            "Epoch: 221, Loss: 0.6573067874111245\n",
            "Epoch: 222, Loss: 0.6572752284098962\n",
            "Epoch: 223, Loss: 0.657244044056887\n",
            "Epoch: 224, Loss: 0.6572132284337973\n",
            "Epoch: 225, Loss: 0.657182775732076\n",
            "Epoch: 226, Loss: 0.6571526802505366\n",
            "Epoch: 227, Loss: 0.657122936393041\n",
            "Epoch: 228, Loss: 0.6570935386662432\n",
            "Epoch: 229, Loss: 0.6570644816773984\n",
            "Epoch: 230, Loss: 0.6570357601322269\n",
            "Epoch: 231, Loss: 0.6570073688328356\n",
            "Epoch: 232, Loss: 0.6569793026756958\n",
            "Epoch: 233, Loss: 0.6569515566496698\n",
            "Epoch: 234, Loss: 0.6569241258340921\n",
            "Epoch: 235, Loss: 0.6568970053968973\n",
            "Epoch: 236, Loss: 0.6568701905927956\n",
            "Epoch: 237, Loss: 0.6568436767614939\n",
            "Epoch: 238, Loss: 0.6568174593259622\n",
            "Epoch: 239, Loss: 0.6567915337907411\n",
            "Epoch: 240, Loss: 0.6567658957402913\n",
            "Epoch: 241, Loss: 0.6567405408373834\n",
            "Epoch: 242, Loss: 0.6567154648215267\n",
            "Epoch: 243, Loss: 0.6566906635074328\n",
            "Epoch: 244, Loss: 0.6566661327835205\n",
            "Epoch: 245, Loss: 0.6566418686104506\n",
            "Epoch: 246, Loss: 0.6566178670196986\n",
            "Epoch: 247, Loss: 0.6565941241121585\n",
            "Epoch: 248, Loss: 0.65657063605678\n",
            "Epoch: 249, Loss: 0.6565473990892354\n",
            "Epoch: 250, Loss: 0.6565244095106183\n",
            "Epoch: 251, Loss: 0.6565016636861705\n",
            "Epoch: 252, Loss: 0.6564791580440387\n",
            "Epoch: 253, Loss: 0.6564568890740571\n",
            "Epoch: 254, Loss: 0.6564348533265587\n",
            "Epoch: 255, Loss: 0.6564130474112125\n",
            "Epoch: 256, Loss: 0.6563914679958848\n",
            "Epoch: 257, Loss: 0.6563701118055276\n",
            "Epoch: 258, Loss: 0.6563489756210888\n",
            "Epoch: 259, Loss: 0.6563280562784479\n",
            "Epoch: 260, Loss: 0.6563073506673732\n",
            "Epoch: 261, Loss: 0.6562868557305018\n",
            "Epoch: 262, Loss: 0.6562665684623409\n",
            "Epoch: 263, Loss: 0.6562464859082917\n",
            "Epoch: 264, Loss: 0.6562266051636912\n",
            "Epoch: 265, Loss: 0.6562069233728772\n",
            "Epoch: 266, Loss: 0.6561874377282698\n",
            "Epoch: 267, Loss: 0.6561681454694746\n",
            "Epoch: 268, Loss: 0.6561490438824032\n",
            "Epoch: 269, Loss: 0.6561301302984115\n",
            "Epoch: 270, Loss: 0.6561114020934569\n",
            "Epoch: 271, Loss: 0.6560928566872716\n",
            "Epoch: 272, Loss: 0.656074491542554\n",
            "Epoch: 273, Loss: 0.6560563041641748\n",
            "Epoch: 274, Loss: 0.6560382920984015\n",
            "Epoch: 275, Loss: 0.6560204529321362\n",
            "Epoch: 276, Loss: 0.6560027842921706\n",
            "Epoch: 277, Loss: 0.655985283844455\n",
            "Epoch: 278, Loss: 0.6559679492933822\n",
            "Epoch: 279, Loss: 0.6559507783810854\n",
            "Epoch: 280, Loss: 0.6559337688867508\n",
            "Epoch: 281, Loss: 0.6559169186259431\n",
            "Epoch: 282, Loss: 0.6559002254499445\n",
            "Epoch: 283, Loss: 0.6558836872451068\n",
            "Epoch: 284, Loss: 0.6558673019322169\n",
            "Epoch: 285, Loss: 0.655851067465874\n",
            "Epoch: 286, Loss: 0.6558349818338779\n",
            "Epoch: 287, Loss: 0.6558190430566327\n",
            "Epoch: 288, Loss: 0.6558032491865583\n",
            "Epoch: 289, Loss: 0.6557875983075154\n",
            "Epoch: 290, Loss: 0.6557720885342416\n",
            "Epoch: 291, Loss: 0.6557567180117978\n",
            "Epoch: 292, Loss: 0.6557414849150254\n",
            "Epoch: 293, Loss: 0.6557263874480149\n",
            "Epoch: 294, Loss: 0.6557114238435826\n",
            "Epoch: 295, Loss: 0.6556965923627602\n",
            "Epoch: 296, Loss: 0.6556818912942917\n",
            "Epoch: 297, Loss: 0.6556673189541411\n",
            "Epoch: 298, Loss: 0.6556528736850098\n",
            "Epoch: 299, Loss: 0.6556385538558623\n",
            "Epoch: 300, Loss: 0.6556243578614612\n",
            "Epoch: 301, Loss: 0.6556102841219119\n",
            "Epoch: 302, Loss: 0.6555963310822146\n",
            "Epoch: 303, Loss: 0.6555824972118248\n",
            "Epoch: 304, Loss: 0.6555687810042254\n",
            "Epoch: 305, Loss: 0.6555551809765005\n",
            "Epoch: 306, Loss: 0.6555416956689234\n",
            "Epoch: 307, Loss: 0.6555283236445493\n",
            "Epoch: 308, Loss: 0.6555150634888166\n",
            "Epoch: 309, Loss: 0.6555019138091542\n",
            "Epoch: 310, Loss: 0.6554888732345987\n",
            "Epoch: 311, Loss: 0.655475940415416\n",
            "Epoch: 312, Loss: 0.6554631140227329\n",
            "Epoch: 313, Loss: 0.6554503927481723\n",
            "Epoch: 314, Loss: 0.6554377753034986\n",
            "Epoch: 315, Loss: 0.6554252604202663\n",
            "Epoch: 316, Loss: 0.6554128468494784\n",
            "Epoch: 317, Loss: 0.6554005333612488\n",
            "Epoch: 318, Loss: 0.6553883187444719\n",
            "Epoch: 319, Loss: 0.6553762018064981\n",
            "Epoch: 320, Loss: 0.6553641813728152\n",
            "Epoch: 321, Loss: 0.6553522562867369\n",
            "Epoch: 322, Loss: 0.6553404254090947\n",
            "Epoch: 323, Loss: 0.6553286876179377\n",
            "Epoch: 324, Loss: 0.6553170418082369\n",
            "Epoch: 325, Loss: 0.6553054868915945\n",
            "Epoch: 326, Loss: 0.6552940217959602\n",
            "Epoch: 327, Loss: 0.6552826454653509\n",
            "Epoch: 328, Loss: 0.6552713568595766\n",
            "Epoch: 329, Loss: 0.6552601549539705\n",
            "Epoch: 330, Loss: 0.6552490387391257\n",
            "Epoch: 331, Loss: 0.6552380072206344\n",
            "Epoch: 332, Loss: 0.6552270594188336\n",
            "Epoch: 333, Loss: 0.6552161943685552\n",
            "Epoch: 334, Loss: 0.6552054111188798\n",
            "Epoch: 335, Loss: 0.6551947087328955\n",
            "Epoch: 336, Loss: 0.6551840862874619\n",
            "Epoch: 337, Loss: 0.6551735428729769\n",
            "Epoch: 338, Loss: 0.655163077593149\n",
            "Epoch: 339, Loss: 0.6551526895647725\n",
            "Epoch: 340, Loss: 0.6551423779175081\n",
            "Epoch: 341, Loss: 0.6551321417936669\n",
            "Epoch: 342, Loss: 0.6551219803479977\n",
            "Epoch: 343, Loss: 0.6551118927474798\n",
            "Epoch: 344, Loss: 0.6551018781711173\n",
            "Epoch: 345, Loss: 0.6550919358097383\n",
            "Epoch: 346, Loss: 0.6550820648657995\n",
            "Epoch: 347, Loss: 0.6550722645531893\n",
            "Epoch: 348, Loss: 0.6550625340970418\n",
            "Epoch: 349, Loss: 0.6550528727335462\n",
            "Epoch: 350, Loss: 0.6550432797097657\n",
            "Epoch: 351, Loss: 0.655033754283457\n",
            "Epoch: 352, Loss: 0.6550242957228929\n",
            "Epoch: 353, Loss: 0.655014903306689\n",
            "Epoch: 354, Loss: 0.6550055763236335\n",
            "Epoch: 355, Loss: 0.6549963140725192\n",
            "Epoch: 356, Loss: 0.6549871158619789\n",
            "Epoch: 357, Loss: 0.6549779810103242\n",
            "Epoch: 358, Loss: 0.654968908845387\n",
            "Epoch: 359, Loss: 0.6549598987043627\n",
            "Epoch: 360, Loss: 0.6549509499336585\n",
            "Epoch: 361, Loss: 0.6549420618887416\n",
            "Epoch: 362, Loss: 0.6549332339339929\n",
            "Epoch: 363, Loss: 0.6549244654425611\n",
            "Epoch: 364, Loss: 0.6549157557962201\n",
            "Epoch: 365, Loss: 0.6549071043852301\n",
            "Epoch: 366, Loss: 0.6548985106081989\n",
            "Epoch: 367, Loss: 0.6548899738719476\n",
            "Epoch: 368, Loss: 0.6548814935913781\n",
            "Epoch: 369, Loss: 0.6548730691893423\n",
            "Epoch: 370, Loss: 0.654864700096514\n",
            "Epoch: 371, Loss: 0.6548563857512646\n",
            "Epoch: 372, Loss: 0.6548481255995374\n",
            "Epoch: 373, Loss: 0.6548399190947279\n",
            "Epoch: 374, Loss: 0.6548317656975643\n",
            "Epoch: 375, Loss: 0.6548236648759903\n",
            "Epoch: 376, Loss: 0.6548156161050493\n",
            "Epoch: 377, Loss: 0.6548076188667733\n",
            "Epoch: 378, Loss: 0.6547996726500694\n",
            "Epoch: 379, Loss: 0.6547917769506131\n",
            "Epoch: 380, Loss: 0.6547839312707391\n",
            "Epoch: 381, Loss: 0.6547761351193374\n",
            "Epoch: 382, Loss: 0.6547683880117496\n",
            "Epoch: 383, Loss: 0.6547606894696667\n",
            "Epoch: 384, Loss: 0.6547530390210293\n",
            "Epoch: 385, Loss: 0.6547454361999304\n",
            "Epoch: 386, Loss: 0.6547378805465174\n",
            "Epoch: 387, Loss: 0.6547303716068993\n",
            "Epoch: 388, Loss: 0.6547229089330514\n",
            "Epoch: 389, Loss: 0.654715492082726\n",
            "Epoch: 390, Loss: 0.6547081206193606\n",
            "Epoch: 391, Loss: 0.6547007941119912\n",
            "Epoch: 392, Loss: 0.6546935121351638\n",
            "Epoch: 393, Loss: 0.6546862742688508\n",
            "Epoch: 394, Loss: 0.6546790800983661\n",
            "Epoch: 395, Loss: 0.6546719292142826\n",
            "Epoch: 396, Loss: 0.654664821212352\n",
            "Epoch: 397, Loss: 0.6546577556934252\n",
            "Epoch: 398, Loss: 0.6546507322633726\n",
            "Epoch: 399, Loss: 0.6546437505330092\n",
            "Epoch: 400, Loss: 0.654636810118018\n",
            "Epoch: 401, Loss: 0.654629910638876\n",
            "Epoch: 402, Loss: 0.6546230517207811\n",
            "Epoch: 403, Loss: 0.6546162329935806\n",
            "Epoch: 404, Loss: 0.6546094540917006\n",
            "Epoch: 405, Loss: 0.6546027146540762\n",
            "Epoch: 406, Loss: 0.6545960143240845\n",
            "Epoch: 407, Loss: 0.6545893527494769\n",
            "Epoch: 408, Loss: 0.6545827295823128\n",
            "Epoch: 409, Loss: 0.6545761444788961\n",
            "Epoch: 410, Loss: 0.6545695970997106\n",
            "Epoch: 411, Loss: 0.6545630871093582\n",
            "Epoch: 412, Loss: 0.6545566141764969\n",
            "Epoch: 413, Loss: 0.6545501779737807\n",
            "Epoch: 414, Loss: 0.6545437781778\n",
            "Epoch: 415, Loss: 0.654537414469023\n",
            "Epoch: 416, Loss: 0.6545310865317394\n",
            "Epoch: 417, Loss: 0.6545247940540024\n",
            "Epoch: 418, Loss: 0.6545185367275743\n",
            "Epoch: 419, Loss: 0.654512314247871\n",
            "Epoch: 420, Loss: 0.6545061263139101\n",
            "Epoch: 421, Loss: 0.6544999726282555\n",
            "Epoch: 422, Loss: 0.6544938528969684\n",
            "Epoch: 423, Loss: 0.6544877668295537\n",
            "Epoch: 424, Loss: 0.6544817141389117\n",
            "Epoch: 425, Loss: 0.6544756945412884\n",
            "Epoch: 426, Loss: 0.6544697077562259\n",
            "Epoch: 427, Loss: 0.6544637535065163\n",
            "Epoch: 428, Loss: 0.6544578315181538\n",
            "Epoch: 429, Loss: 0.6544519415202886\n",
            "Epoch: 430, Loss: 0.6544460832451825\n",
            "Epoch: 431, Loss: 0.6544402564281626\n",
            "Epoch: 432, Loss: 0.6544344608075795\n",
            "Epoch: 433, Loss: 0.6544286961247618\n",
            "Epoch: 434, Loss: 0.6544229621239765\n",
            "Epoch: 435, Loss: 0.6544172585523846\n",
            "Epoch: 436, Loss: 0.6544115851600012\n",
            "Epoch: 437, Loss: 0.6544059416996555\n",
            "Epoch: 438, Loss: 0.6544003279269506\n",
            "Epoch: 439, Loss: 0.6543947436002242\n",
            "Epoch: 440, Loss: 0.6543891884805109\n",
            "Epoch: 441, Loss: 0.654383662331504\n",
            "Epoch: 442, Loss: 0.6543781649195174\n",
            "Epoch: 443, Loss: 0.6543726960134512\n",
            "Epoch: 444, Loss: 0.6543672553847536\n",
            "Epoch: 445, Loss: 0.6543618428073863\n",
            "Epoch: 446, Loss: 0.6543564580577904\n",
            "Epoch: 447, Loss: 0.6543511009148506\n",
            "Epoch: 448, Loss: 0.6543457711598626\n",
            "Epoch: 449, Loss: 0.6543404685765\n",
            "Epoch: 450, Loss: 0.6543351929507807\n",
            "Epoch: 451, Loss: 0.6543299440710358\n",
            "Epoch: 452, Loss: 0.6543247217278779\n",
            "Epoch: 453, Loss: 0.6543195257141687\n",
            "Epoch: 454, Loss: 0.65431435582499\n",
            "Epoch: 455, Loss: 0.6543092118576135\n",
            "Epoch: 456, Loss: 0.6543040936114698\n",
            "Epoch: 457, Loss: 0.6542990008881205\n",
            "Epoch: 458, Loss: 0.6542939334912294\n",
            "Epoch: 459, Loss: 0.6542888912265332\n",
            "Epoch: 460, Loss: 0.6542838739018159\n",
            "Epoch: 461, Loss: 0.6542788813268782\n",
            "Epoch: 462, Loss: 0.6542739133135141\n",
            "Epoch: 463, Loss: 0.6542689696754815\n",
            "Epoch: 464, Loss: 0.6542640502284782\n",
            "Epoch: 465, Loss: 0.6542591547901153\n",
            "Epoch: 466, Loss: 0.6542542831798916\n",
            "Epoch: 467, Loss: 0.6542494352191695\n",
            "Epoch: 468, Loss: 0.6542446107311497\n",
            "Epoch: 469, Loss: 0.6542398095408486\n",
            "Epoch: 470, Loss: 0.6542350314750724\n",
            "Epoch: 471, Loss: 0.6542302763623957\n",
            "Epoch: 472, Loss: 0.654225544033137\n",
            "Epoch: 473, Loss: 0.654220834319338\n",
            "Epoch: 474, Loss: 0.6542161470547383\n",
            "Epoch: 475, Loss: 0.6542114820747568\n",
            "Epoch: 476, Loss: 0.6542068392164677\n",
            "Epoch: 477, Loss: 0.6542022183185804\n",
            "Epoch: 478, Loss: 0.654197619221418\n",
            "Epoch: 479, Loss: 0.6541930417668969\n",
            "Epoch: 480, Loss: 0.6541884857985069\n",
            "Epoch: 481, Loss: 0.65418395116129\n",
            "Epoch: 482, Loss: 0.6541794377018222\n",
            "Epoch: 483, Loss: 0.6541749452681933\n",
            "Epoch: 484, Loss: 0.6541704737099872\n",
            "Epoch: 485, Loss: 0.6541660228782644\n",
            "Epoch: 486, Loss: 0.654161592625543\n",
            "Epoch: 487, Loss: 0.6541571828057795\n",
            "Epoch: 488, Loss: 0.6541527932743524\n",
            "Epoch: 489, Loss: 0.6541484238880435\n",
            "Epoch: 490, Loss: 0.6541440745050203\n",
            "Epoch: 491, Loss: 0.65413974498482\n",
            "Epoch: 492, Loss: 0.6541354351883305\n",
            "Epoch: 493, Loss: 0.6541311449777766\n",
            "Epoch: 494, Loss: 0.6541268742167008\n",
            "Epoch: 495, Loss: 0.6541226227699488\n",
            "Epoch: 496, Loss: 0.654118390503653\n",
            "Epoch: 497, Loss: 0.6541141772852169\n",
            "Epoch: 498, Loss: 0.6541099829832996\n",
            "Epoch: 499, Loss: 0.6541058074678007\n",
            "Epoch: 500, Loss: 0.6541016506098449\n",
            "Epoch: 501, Loss: 0.6540975122817676\n",
            "Epoch: 502, Loss: 0.6540933923571005\n",
            "Epoch: 503, Loss: 0.6540892907105563\n",
            "Epoch: 504, Loss: 0.6540852072180158\n",
            "Epoch: 505, Loss: 0.654081141756513\n",
            "Epoch: 506, Loss: 0.6540770942042214\n",
            "Epoch: 507, Loss: 0.6540730644404413\n",
            "Epoch: 508, Loss: 0.6540690523455855\n",
            "Epoch: 509, Loss: 0.6540650578011669\n",
            "Epoch: 510, Loss: 0.6540610806897844\n",
            "Epoch: 511, Loss: 0.6540571208951119\n",
            "Epoch: 512, Loss: 0.6540531783018836\n",
            "Epoch: 513, Loss: 0.6540492527958833\n",
            "Epoch: 514, Loss: 0.6540453442639311\n",
            "Epoch: 515, Loss: 0.6540414525938727\n",
            "Epoch: 516, Loss: 0.654037577674565\n",
            "Epoch: 517, Loss: 0.6540337193958674\n",
            "Epoch: 518, Loss: 0.6540298776486277\n",
            "Epoch: 519, Loss: 0.6540260523246721\n",
            "Epoch: 520, Loss: 0.6540222433167939\n",
            "Epoch: 521, Loss: 0.654018450518742\n",
            "Epoch: 522, Loss: 0.6540146738252095\n",
            "Epoch: 523, Loss: 0.6540109131318245\n",
            "Epoch: 524, Loss: 0.6540071683351377\n",
            "Epoch: 525, Loss: 0.6540034393326137\n",
            "Epoch: 526, Loss: 0.653999726022619\n",
            "Epoch: 527, Loss: 0.6539960283044124\n",
            "Epoch: 528, Loss: 0.6539923460781357\n",
            "Epoch: 529, Loss: 0.6539886792448032\n",
            "Epoch: 530, Loss: 0.6539850277062911\n",
            "Epoch: 531, Loss: 0.6539813913653298\n",
            "Epoch: 532, Loss: 0.6539777701254924\n",
            "Epoch: 533, Loss: 0.6539741638911868\n",
            "Epoch: 534, Loss: 0.6539705725676457\n",
            "Epoch: 535, Loss: 0.6539669960609179\n",
            "Epoch: 536, Loss: 0.6539634342778586\n",
            "Epoch: 537, Loss: 0.6539598871261213\n",
            "Epoch: 538, Loss: 0.653956354514149\n",
            "Epoch: 539, Loss: 0.6539528363511651\n",
            "Epoch: 540, Loss: 0.6539493325471651\n",
            "Epoch: 541, Loss: 0.6539458430129081\n",
            "Epoch: 542, Loss: 0.6539423676599089\n",
            "Epoch: 543, Loss: 0.6539389064004295\n",
            "Epoch: 544, Loss: 0.6539354591474712\n",
            "Epoch: 545, Loss: 0.6539320258147661\n",
            "Epoch: 546, Loss: 0.65392860631677\n",
            "Epoch: 547, Loss: 0.6539252005686543\n",
            "Epoch: 548, Loss: 0.6539218084862983\n",
            "Epoch: 549, Loss: 0.653918429986282\n",
            "Epoch: 550, Loss: 0.653915064985878\n",
            "Epoch: 551, Loss: 0.6539117134030445\n",
            "Epoch: 552, Loss: 0.6539083751564186\n",
            "Epoch: 553, Loss: 0.6539050501653083\n",
            "Epoch: 554, Loss: 0.6539017383496855\n",
            "Epoch: 555, Loss: 0.6538984396301797\n",
            "Epoch: 556, Loss: 0.6538951539280704\n",
            "Epoch: 557, Loss: 0.6538918811652805\n",
            "Epoch: 558, Loss: 0.6538886212643705\n",
            "Epoch: 559, Loss: 0.65388537414853\n",
            "Epoch: 560, Loss: 0.6538821397415727\n",
            "Epoch: 561, Loss: 0.6538789179679301\n",
            "Epoch: 562, Loss: 0.6538757087526434\n",
            "Epoch: 563, Loss: 0.653872512021359\n",
            "Epoch: 564, Loss: 0.6538693277003216\n",
            "Epoch: 565, Loss: 0.653866155716368\n",
            "Epoch: 566, Loss: 0.6538629959969209\n",
            "Epoch: 567, Loss: 0.6538598484699838\n",
            "Epoch: 568, Loss: 0.6538567130641337\n",
            "Epoch: 569, Loss: 0.6538535897085168\n",
            "Epoch: 570, Loss: 0.6538504783328414\n",
            "Epoch: 571, Loss: 0.6538473788673732\n",
            "Epoch: 572, Loss: 0.6538442912429291\n",
            "Epoch: 573, Loss: 0.6538412153908718\n",
            "Epoch: 574, Loss: 0.6538381512431047\n",
            "Epoch: 575, Loss: 0.653835098732066\n",
            "Epoch: 576, Loss: 0.6538320577907236\n",
            "Epoch: 577, Loss: 0.6538290283525698\n",
            "Epoch: 578, Loss: 0.6538260103516159\n",
            "Epoch: 579, Loss: 0.6538230037223873\n",
            "Epoch: 580, Loss: 0.653820008399919\n",
            "Epoch: 581, Loss: 0.6538170243197489\n",
            "Epoch: 582, Loss: 0.6538140514179144\n",
            "Epoch: 583, Loss: 0.6538110896309474\n",
            "Epoch: 584, Loss: 0.6538081388958682\n",
            "Epoch: 585, Loss: 0.6538051991501823\n",
            "Epoch: 586, Loss: 0.6538022703318745\n",
            "Epoch: 587, Loss: 0.6537993523794053\n",
            "Epoch: 588, Loss: 0.6537964452317051\n",
            "Epoch: 589, Loss: 0.6537935488281702\n",
            "Epoch: 590, Loss: 0.6537906631086591\n",
            "Epoch: 591, Loss: 0.6537877880134862\n",
            "Epoch: 592, Loss: 0.6537849234834197\n",
            "Epoch: 593, Loss: 0.6537820694596751\n",
            "Epoch: 594, Loss: 0.6537792258839124\n",
            "Epoch: 595, Loss: 0.653776392698231\n",
            "Epoch: 596, Loss: 0.6537735698451663\n",
            "Epoch: 597, Loss: 0.653770757267685\n",
            "Epoch: 598, Loss: 0.6537679549091807\n",
            "Epoch: 599, Loss: 0.6537651627134708\n",
            "Epoch: 600, Loss: 0.6537623806247918\n",
            "Epoch: 601, Loss: 0.6537596085877958\n",
            "Epoch: 602, Loss: 0.6537568465475456\n",
            "Epoch: 603, Loss: 0.6537540944495126\n",
            "Epoch: 604, Loss: 0.6537513522395711\n",
            "Epoch: 605, Loss: 0.6537486198639961\n",
            "Epoch: 606, Loss: 0.6537458972694583\n",
            "Epoch: 607, Loss: 0.6537431844030215\n",
            "Epoch: 608, Loss: 0.6537404812121381\n",
            "Epoch: 609, Loss: 0.6537377876446462\n",
            "Epoch: 610, Loss: 0.6537351036487651\n",
            "Epoch: 611, Loss: 0.653732429173093\n",
            "Epoch: 612, Loss: 0.653729764166603\n",
            "Epoch: 613, Loss: 0.6537271085786387\n",
            "Epoch: 614, Loss: 0.6537244623589126\n",
            "Epoch: 615, Loss: 0.6537218254575012\n",
            "Epoch: 616, Loss: 0.6537191978248427\n",
            "Epoch: 617, Loss: 0.6537165794117331\n",
            "Epoch: 618, Loss: 0.6537139701693233\n",
            "Epoch: 619, Loss: 0.6537113700491153\n",
            "Epoch: 620, Loss: 0.6537087790029599\n",
            "Epoch: 621, Loss: 0.6537061969830529\n",
            "Epoch: 622, Loss: 0.6537036239419323\n",
            "Epoch: 623, Loss: 0.6537010598324753\n",
            "Epoch: 624, Loss: 0.6536985046078945\n",
            "Epoch: 625, Loss: 0.653695958221736\n",
            "Epoch: 626, Loss: 0.653693420627876\n",
            "Epoch: 627, Loss: 0.6536908917805175\n",
            "Epoch: 628, Loss: 0.6536883716341876\n",
            "Epoch: 629, Loss: 0.6536858601437349\n",
            "Epoch: 630, Loss: 0.653683357264326\n",
            "Epoch: 631, Loss: 0.653680862951444\n",
            "Epoch: 632, Loss: 0.6536783771608838\n",
            "Epoch: 633, Loss: 0.6536758998487513\n",
            "Epoch: 634, Loss: 0.6536734309714589\n",
            "Epoch: 635, Loss: 0.6536709704857245\n",
            "Epoch: 636, Loss: 0.6536685183485673\n",
            "Epoch: 637, Loss: 0.6536660745173061\n",
            "Epoch: 638, Loss: 0.6536636389495568\n",
            "Epoch: 639, Loss: 0.6536612116032288\n",
            "Epoch: 640, Loss: 0.6536587924365234\n",
            "Epoch: 641, Loss: 0.6536563814079315\n",
            "Epoch: 642, Loss: 0.6536539784762294\n",
            "Epoch: 643, Loss: 0.6536515836004789\n",
            "Epoch: 644, Loss: 0.6536491967400223\n",
            "Epoch: 645, Loss: 0.6536468178544816\n",
            "Epoch: 646, Loss: 0.6536444469037557\n",
            "Epoch: 647, Loss: 0.6536420838480178\n",
            "Epoch: 648, Loss: 0.6536397286477134\n",
            "Epoch: 649, Loss: 0.6536373812635571\n",
            "Epoch: 650, Loss: 0.6536350416565321\n",
            "Epoch: 651, Loss: 0.6536327097878859\n",
            "Epoch: 652, Loss: 0.6536303856191297\n",
            "Epoch: 653, Loss: 0.6536280691120345\n",
            "Epoch: 654, Loss: 0.6536257602286305\n",
            "Epoch: 655, Loss: 0.6536234589312041\n",
            "Epoch: 656, Loss: 0.6536211651822956\n",
            "Epoch: 657, Loss: 0.6536188789446977\n",
            "Epoch: 658, Loss: 0.653616600181453\n",
            "Epoch: 659, Loss: 0.6536143288558515\n",
            "Epoch: 660, Loss: 0.6536120649314294\n",
            "Epoch: 661, Loss: 0.6536098083719664\n",
            "Epoch: 662, Loss: 0.6536075591414836\n",
            "Epoch: 663, Loss: 0.6536053172042423\n",
            "Epoch: 664, Loss: 0.6536030825247411\n",
            "Epoch: 665, Loss: 0.6536008550677141\n",
            "Epoch: 666, Loss: 0.6535986347981297\n",
            "Epoch: 667, Loss: 0.6535964216811875\n",
            "Epoch: 668, Loss: 0.6535942156823171\n",
            "Epoch: 669, Loss: 0.6535920167671764\n",
            "Epoch: 670, Loss: 0.6535898249016495\n",
            "Epoch: 671, Loss: 0.6535876400518438\n",
            "Epoch: 672, Loss: 0.6535854621840903\n",
            "Epoch: 673, Loss: 0.6535832912649396\n",
            "Epoch: 674, Loss: 0.653581127261162\n",
            "Epoch: 675, Loss: 0.6535789701397441\n",
            "Epoch: 676, Loss: 0.6535768198678878\n",
            "Epoch: 677, Loss: 0.6535746764130088\n",
            "Epoch: 678, Loss: 0.6535725397427347\n",
            "Epoch: 679, Loss: 0.6535704098249026\n",
            "Epoch: 680, Loss: 0.6535682866275581\n",
            "Epoch: 681, Loss: 0.6535661701189535\n",
            "Epoch: 682, Loss: 0.6535640602675462\n",
            "Epoch: 683, Loss: 0.6535619570419968\n",
            "Epoch: 684, Loss: 0.6535598604111678\n",
            "Epoch: 685, Loss: 0.6535577703441212\n",
            "Epoch: 686, Loss: 0.6535556868101184\n",
            "Epoch: 687, Loss: 0.653553609778617\n",
            "Epoch: 688, Loss: 0.6535515392192698\n",
            "Epoch: 689, Loss: 0.6535494751019238\n",
            "Epoch: 690, Loss: 0.6535474173966184\n",
            "Epoch: 691, Loss: 0.6535453660735829\n",
            "Epoch: 692, Loss: 0.6535433211032364\n",
            "Epoch: 693, Loss: 0.6535412824561856\n",
            "Epoch: 694, Loss: 0.653539250103223\n",
            "Epoch: 695, Loss: 0.6535372240153264\n",
            "Epoch: 696, Loss: 0.6535352041636566\n",
            "Epoch: 697, Loss: 0.6535331905195558\n",
            "Epoch: 698, Loss: 0.6535311830545469\n",
            "Epoch: 699, Loss: 0.6535291817403323\n",
            "Epoch: 700, Loss: 0.6535271865487914\n",
            "Epoch: 701, Loss: 0.6535251974519796\n",
            "Epoch: 702, Loss: 0.6535232144221276\n",
            "Epoch: 703, Loss: 0.653521237431639\n",
            "Epoch: 704, Loss: 0.6535192664530901\n",
            "Epoch: 705, Loss: 0.6535173014592277\n",
            "Epoch: 706, Loss: 0.6535153424229674\n",
            "Epoch: 707, Loss: 0.653513389317394\n",
            "Epoch: 708, Loss: 0.6535114421157583\n",
            "Epoch: 709, Loss: 0.6535095007914771\n",
            "Epoch: 710, Loss: 0.6535075653181309\n",
            "Epoch: 711, Loss: 0.6535056356694636\n",
            "Epoch: 712, Loss: 0.6535037118193805\n",
            "Epoch: 713, Loss: 0.653501793741948\n",
            "Epoch: 714, Loss: 0.6534998814113905\n",
            "Epoch: 715, Loss: 0.6534979748020919\n",
            "Epoch: 716, Loss: 0.653496073888592\n",
            "Epoch: 717, Loss: 0.6534941786455861\n",
            "Epoch: 718, Loss: 0.6534922890479244\n",
            "Epoch: 719, Loss: 0.6534904050706104\n",
            "Epoch: 720, Loss: 0.653488526688799\n",
            "Epoch: 721, Loss: 0.6534866538777966\n",
            "Epoch: 722, Loss: 0.6534847866130593\n",
            "Epoch: 723, Loss: 0.6534829248701917\n",
            "Epoch: 724, Loss: 0.6534810686249459\n",
            "Epoch: 725, Loss: 0.6534792178532205\n",
            "Epoch: 726, Loss: 0.6534773725310593\n",
            "Epoch: 727, Loss: 0.6534755326346505\n",
            "Epoch: 728, Loss: 0.6534736981403251\n",
            "Epoch: 729, Loss: 0.653471869024556\n",
            "Epoch: 730, Loss: 0.653470045263958\n",
            "Epoch: 731, Loss: 0.6534682268352845\n",
            "Epoch: 732, Loss: 0.653466413715429\n",
            "Epoch: 733, Loss: 0.653464605881422\n",
            "Epoch: 734, Loss: 0.6534628033104309\n",
            "Epoch: 735, Loss: 0.6534610059797592\n",
            "Epoch: 736, Loss: 0.653459213866845\n",
            "Epoch: 737, Loss: 0.6534574269492602\n",
            "Epoch: 738, Loss: 0.6534556452047092\n",
            "Epoch: 739, Loss: 0.6534538686110285\n",
            "Epoch: 740, Loss: 0.6534520971461857\n",
            "Epoch: 741, Loss: 0.6534503307882772\n",
            "Epoch: 742, Loss: 0.6534485695155294\n",
            "Epoch: 743, Loss: 0.6534468133062964\n",
            "Epoch: 744, Loss: 0.6534450621390584\n",
            "Epoch: 745, Loss: 0.6534433159924228\n",
            "Epoch: 746, Loss: 0.6534415748451218\n",
            "Epoch: 747, Loss: 0.6534398386760111\n",
            "Epoch: 748, Loss: 0.6534381074640708\n",
            "Epoch: 749, Loss: 0.6534363811884027\n",
            "Epoch: 750, Loss: 0.6534346598282306\n",
            "Epoch: 751, Loss: 0.6534329433628981\n",
            "Epoch: 752, Loss: 0.6534312317718692\n",
            "Epoch: 753, Loss: 0.653429525034727\n",
            "Epoch: 754, Loss: 0.6534278231311718\n",
            "Epoch: 755, Loss: 0.6534261260410217\n",
            "Epoch: 756, Loss: 0.6534244337442107\n",
            "Epoch: 757, Loss: 0.6534227462207886\n",
            "Epoch: 758, Loss: 0.6534210634509195\n",
            "Epoch: 759, Loss: 0.6534193854148815\n",
            "Epoch: 760, Loss: 0.653417712093066\n",
            "Epoch: 761, Loss: 0.6534160434659757\n",
            "Epoch: 762, Loss: 0.6534143795142252\n",
            "Epoch: 763, Loss: 0.6534127202185399\n",
            "Epoch: 764, Loss: 0.6534110655597543\n",
            "Epoch: 765, Loss: 0.6534094155188123\n",
            "Epoch: 766, Loss: 0.653407770076766\n",
            "Epoch: 767, Loss: 0.6534061292147748\n",
            "Epoch: 768, Loss: 0.6534044929141049\n",
            "Epoch: 769, Loss: 0.653402861156128\n",
            "Epoch: 770, Loss: 0.6534012339223215\n",
            "Epoch: 771, Loss: 0.6533996111942669\n",
            "Epoch: 772, Loss: 0.6533979929536492\n",
            "Epoch: 773, Loss: 0.6533963791822566\n",
            "Epoch: 774, Loss: 0.6533947698619791\n",
            "Epoch: 775, Loss: 0.6533931649748087\n",
            "Epoch: 776, Loss: 0.6533915645028376\n",
            "Epoch: 777, Loss: 0.6533899684282587\n",
            "Epoch: 778, Loss: 0.6533883767333634\n",
            "Epoch: 779, Loss: 0.6533867894005421\n",
            "Epoch: 780, Loss: 0.6533852064122835\n",
            "Epoch: 781, Loss: 0.6533836277511731\n",
            "Epoch: 782, Loss: 0.6533820533998929\n",
            "Epoch: 783, Loss: 0.6533804833412212\n",
            "Epoch: 784, Loss: 0.6533789175580311\n",
            "Epoch: 785, Loss: 0.6533773560332905\n",
            "Epoch: 786, Loss: 0.6533757987500612\n",
            "Epoch: 787, Loss: 0.6533742456914982\n",
            "Epoch: 788, Loss: 0.6533726968408488\n",
            "Epoch: 789, Loss: 0.6533711521814525\n",
            "Epoch: 790, Loss: 0.65336961169674\n",
            "Epoch: 791, Loss: 0.6533680753702333\n",
            "Epoch: 792, Loss: 0.6533665431855433\n",
            "Epoch: 793, Loss: 0.6533650151263711\n",
            "Epoch: 794, Loss: 0.6533634911765066\n",
            "Epoch: 795, Loss: 0.6533619713198272\n",
            "Epoch: 796, Loss: 0.6533604555402989\n",
            "Epoch: 797, Loss: 0.6533589438219739\n",
            "Epoch: 798, Loss: 0.6533574361489907\n",
            "Epoch: 799, Loss: 0.6533559325055743\n",
            "Epoch: 800, Loss: 0.6533544328760346\n",
            "Epoch: 801, Loss: 0.6533529372447654\n",
            "Epoch: 802, Loss: 0.6533514455962459\n",
            "Epoch: 803, Loss: 0.6533499579150374\n",
            "Epoch: 804, Loss: 0.6533484741857848\n",
            "Epoch: 805, Loss: 0.6533469943932151\n",
            "Epoch: 806, Loss: 0.6533455185221373\n",
            "Epoch: 807, Loss: 0.6533440465574415\n",
            "Epoch: 808, Loss: 0.6533425784840979\n",
            "Epoch: 809, Loss: 0.653341114287158\n",
            "Epoch: 810, Loss: 0.6533396539517516\n",
            "Epoch: 811, Loss: 0.6533381974630884\n",
            "Epoch: 812, Loss: 0.653336744806456\n",
            "Epoch: 813, Loss: 0.65333529596722\n",
            "Epoch: 814, Loss: 0.6533338509308242\n",
            "Epoch: 815, Loss: 0.6533324096827883\n",
            "Epoch: 816, Loss: 0.653330972208709\n",
            "Epoch: 817, Loss: 0.6533295384942585\n",
            "Epoch: 818, Loss: 0.6533281085251846\n",
            "Epoch: 819, Loss: 0.6533266822873101\n",
            "Epoch: 820, Loss: 0.6533252597665317\n",
            "Epoch: 821, Loss: 0.6533238409488205\n",
            "Epoch: 822, Loss: 0.6533224258202202\n",
            "Epoch: 823, Loss: 0.6533210143668484\n",
            "Epoch: 824, Loss: 0.6533196065748944\n",
            "Epoch: 825, Loss: 0.6533182024306194\n",
            "Epoch: 826, Loss: 0.6533168019203559\n",
            "Epoch: 827, Loss: 0.6533154050305086\n",
            "Epoch: 828, Loss: 0.6533140117475505\n",
            "Epoch: 829, Loss: 0.6533126220580266\n",
            "Epoch: 830, Loss: 0.6533112359485505\n",
            "Epoch: 831, Loss: 0.6533098534058049\n",
            "Epoch: 832, Loss: 0.6533084744165415\n",
            "Epoch: 833, Loss: 0.6533070989675797\n",
            "Epoch: 834, Loss: 0.653305727045807\n",
            "Epoch: 835, Loss: 0.6533043586381784\n",
            "Epoch: 836, Loss: 0.6533029937317149\n",
            "Epoch: 837, Loss: 0.6533016323135046\n",
            "Epoch: 838, Loss: 0.6533002743707017\n",
            "Epoch: 839, Loss: 0.6532989198905252\n",
            "Epoch: 840, Loss: 0.6532975688602599\n",
            "Epoch: 841, Loss: 0.6532962212672548\n",
            "Epoch: 842, Loss: 0.6532948770989234\n",
            "Epoch: 843, Loss: 0.6532935363427431\n",
            "Epoch: 844, Loss: 0.6532921989862546\n",
            "Epoch: 845, Loss: 0.6532908650170615\n",
            "Epoch: 846, Loss: 0.6532895344228299\n",
            "Epoch: 847, Loss: 0.653288207191289\n",
            "Epoch: 848, Loss: 0.6532868833102284\n",
            "Epoch: 849, Loss: 0.6532855627675003\n",
            "Epoch: 850, Loss: 0.653284245551017\n",
            "Epoch: 851, Loss: 0.653282931648752\n",
            "Epoch: 852, Loss: 0.6532816210487385\n",
            "Epoch: 853, Loss: 0.6532803137390701\n",
            "Epoch: 854, Loss: 0.6532790097078993\n",
            "Epoch: 855, Loss: 0.6532777089434378\n",
            "Epoch: 856, Loss: 0.6532764114339565\n",
            "Epoch: 857, Loss: 0.6532751171677839\n",
            "Epoch: 858, Loss: 0.6532738261333061\n",
            "Epoch: 859, Loss: 0.653272538318968\n",
            "Epoch: 860, Loss: 0.6532712537132708\n",
            "Epoch: 861, Loss: 0.6532699723047726\n",
            "Epoch: 862, Loss: 0.653268694082088\n",
            "Epoch: 863, Loss: 0.6532674190338876\n",
            "Epoch: 864, Loss: 0.6532661471488983\n",
            "Epoch: 865, Loss: 0.6532648784159015\n",
            "Epoch: 866, Loss: 0.6532636128237345\n",
            "Epoch: 867, Loss: 0.6532623503612883\n",
            "Epoch: 868, Loss: 0.6532610910175093\n",
            "Epoch: 869, Loss: 0.6532598347813972\n",
            "Epoch: 870, Loss: 0.6532585816420056\n",
            "Epoch: 871, Loss: 0.6532573315884409\n",
            "Epoch: 872, Loss: 0.6532560846098635\n",
            "Epoch: 873, Loss: 0.6532548406954857\n",
            "Epoch: 874, Loss: 0.6532535998345717\n",
            "Epoch: 875, Loss: 0.6532523620164387\n",
            "Epoch: 876, Loss: 0.6532511272304551\n",
            "Epoch: 877, Loss: 0.6532498954660405\n",
            "Epoch: 878, Loss: 0.6532486667126657\n",
            "Epoch: 879, Loss: 0.653247440959852\n",
            "Epoch: 880, Loss: 0.6532462181971708\n",
            "Epoch: 881, Loss: 0.6532449984142448\n",
            "Epoch: 882, Loss: 0.6532437816007446\n",
            "Epoch: 883, Loss: 0.653242567746392\n",
            "Epoch: 884, Loss: 0.6532413568409565\n",
            "Epoch: 885, Loss: 0.6532401488742576\n",
            "Epoch: 886, Loss: 0.6532389438361623\n",
            "Epoch: 887, Loss: 0.6532377417165867\n",
            "Epoch: 888, Loss: 0.6532365425054939\n",
            "Epoch: 889, Loss: 0.6532353461928956\n",
            "Epoch: 890, Loss: 0.6532341527688501\n",
            "Epoch: 891, Loss: 0.653232962223463\n",
            "Epoch: 892, Loss: 0.6532317745468869\n",
            "Epoch: 893, Loss: 0.65323058972932\n",
            "Epoch: 894, Loss: 0.6532294077610078\n",
            "Epoch: 895, Loss: 0.6532282286322412\n",
            "Epoch: 896, Loss: 0.6532270523333563\n",
            "Epoch: 897, Loss: 0.6532258788547348\n",
            "Epoch: 898, Loss: 0.6532247081868042\n",
            "Epoch: 899, Loss: 0.6532235403200358\n",
            "Epoch: 900, Loss: 0.6532223752449454\n",
            "Epoch: 901, Loss: 0.6532212129520937\n",
            "Epoch: 902, Loss: 0.6532200534320849\n",
            "Epoch: 903, Loss: 0.6532188966755671\n",
            "Epoch: 904, Loss: 0.6532177426732318\n",
            "Epoch: 905, Loss: 0.6532165914158133\n",
            "Epoch: 906, Loss: 0.6532154428940896\n",
            "Epoch: 907, Loss: 0.6532142970988802\n",
            "Epoch: 908, Loss: 0.6532131540210482\n",
            "Epoch: 909, Loss: 0.6532120136514982\n",
            "Epoch: 910, Loss: 0.6532108759811764\n",
            "Epoch: 911, Loss: 0.6532097410010713\n",
            "Epoch: 912, Loss: 0.6532086087022124\n",
            "Epoch: 913, Loss: 0.6532074790756703\n",
            "Epoch: 914, Loss: 0.6532063521125568\n",
            "Epoch: 915, Loss: 0.6532052278040237\n",
            "Epoch: 916, Loss: 0.6532041061412637\n",
            "Epoch: 917, Loss: 0.6532029871155096\n",
            "Epoch: 918, Loss: 0.6532018707180339\n",
            "Epoch: 919, Loss: 0.653200756940149\n",
            "Epoch: 920, Loss: 0.6531996457732067\n",
            "Epoch: 921, Loss: 0.6531985372085978\n",
            "Epoch: 922, Loss: 0.6531974312377523\n",
            "Epoch: 923, Loss: 0.6531963278521385\n",
            "Epoch: 924, Loss: 0.6531952270432638\n",
            "Epoch: 925, Loss: 0.6531941288026739\n",
            "Epoch: 926, Loss: 0.6531930331219519\n",
            "Epoch: 927, Loss: 0.6531919399927189\n",
            "Epoch: 928, Loss: 0.653190849406634\n",
            "Epoch: 929, Loss: 0.6531897613553935\n",
            "Epoch: 930, Loss: 0.6531886758307306\n",
            "Epoch: 931, Loss: 0.6531875928244162\n",
            "Epoch: 932, Loss: 0.6531865123282566\n",
            "Epoch: 933, Loss: 0.6531854343340961\n",
            "Epoch: 934, Loss: 0.6531843588338141\n",
            "Epoch: 935, Loss: 0.6531832858193268\n",
            "Epoch: 936, Loss: 0.6531822152825859\n",
            "Epoch: 937, Loss: 0.6531811472155791\n",
            "Epoch: 938, Loss: 0.6531800816103288\n",
            "Epoch: 939, Loss: 0.6531790184588939\n",
            "Epoch: 940, Loss: 0.6531779577533672\n",
            "Epoch: 941, Loss: 0.6531768994858768\n",
            "Epoch: 942, Loss: 0.6531758436485857\n",
            "Epoch: 943, Loss: 0.6531747902336906\n",
            "Epoch: 944, Loss: 0.6531737392334234\n",
            "Epoch: 945, Loss: 0.6531726906400487\n",
            "Epoch: 946, Loss: 0.6531716444458664\n",
            "Epoch: 947, Loss: 0.6531706006432093\n",
            "Epoch: 948, Loss: 0.6531695592244438\n",
            "Epoch: 949, Loss: 0.653168520181969\n",
            "Epoch: 950, Loss: 0.6531674835082182\n",
            "Epoch: 951, Loss: 0.6531664491956565\n",
            "Epoch: 952, Loss: 0.6531654172367822\n",
            "Epoch: 953, Loss: 0.6531643876241262\n",
            "Epoch: 954, Loss: 0.6531633603502517\n",
            "Epoch: 955, Loss: 0.6531623354077534\n",
            "Epoch: 956, Loss: 0.6531613127892587\n",
            "Epoch: 957, Loss: 0.6531602924874265\n",
            "Epoch: 958, Loss: 0.6531592744949469\n",
            "Epoch: 959, Loss: 0.6531582588045424\n",
            "Epoch: 960, Loss: 0.6531572454089657\n",
            "Epoch: 961, Loss: 0.653156234301001\n",
            "Epoch: 962, Loss: 0.6531552254734634\n",
            "Epoch: 963, Loss: 0.6531542189191987\n",
            "Epoch: 964, Loss: 0.6531532146310826\n",
            "Epoch: 965, Loss: 0.6531522126020224\n",
            "Epoch: 966, Loss: 0.6531512128249545\n",
            "Epoch: 967, Loss: 0.6531502152928458\n",
            "Epoch: 968, Loss: 0.6531492199986929\n",
            "Epoch: 969, Loss: 0.653148226935522\n",
            "Epoch: 970, Loss: 0.653147236096389\n",
            "Epoch: 971, Loss: 0.6531462474743793\n",
            "Epoch: 972, Loss: 0.653145261062607\n",
            "Epoch: 973, Loss: 0.6531442768542152\n",
            "Epoch: 974, Loss: 0.6531432948423762\n",
            "Epoch: 975, Loss: 0.6531423150202913\n",
            "Epoch: 976, Loss: 0.6531413373811896\n",
            "Epoch: 977, Loss: 0.6531403619183289\n",
            "Epoch: 978, Loss: 0.6531393886249953\n",
            "Epoch: 979, Loss: 0.653138417494503\n",
            "Epoch: 980, Loss: 0.6531374485201937\n",
            "Epoch: 981, Loss: 0.6531364816954371\n",
            "Epoch: 982, Loss: 0.653135517013631\n",
            "Epoch: 983, Loss: 0.6531345544681997\n",
            "Epoch: 984, Loss: 0.6531335940525954\n",
            "Epoch: 985, Loss: 0.6531326357602973\n",
            "Epoch: 986, Loss: 0.6531316795848118\n",
            "Epoch: 987, Loss: 0.6531307255196714\n",
            "Epoch: 988, Loss: 0.6531297735584365\n",
            "Epoch: 989, Loss: 0.6531288236946929\n",
            "Epoch: 990, Loss: 0.6531278759220537\n",
            "Epoch: 991, Loss: 0.6531269302341574\n",
            "Epoch: 992, Loss: 0.6531259866246694\n",
            "Epoch: 993, Loss: 0.6531250450872808\n",
            "Epoch: 994, Loss: 0.6531241056157081\n",
            "Epoch: 995, Loss: 0.6531231682036942\n",
            "Epoch: 996, Loss: 0.6531222328450073\n",
            "Epoch: 997, Loss: 0.6531212995334407\n",
            "Epoch: 998, Loss: 0.6531203682628134\n",
            "Epoch: 999, Loss: 0.6531194390269691\n",
            "Epoch: 1000, Loss: 0.6531185118197771\n",
            "Epoch: 1001, Loss: 0.6531175866351312\n",
            "Epoch: 1002, Loss: 0.6531166634669499\n",
            "Epoch: 1003, Loss: 0.6531157423091762\n",
            "Epoch: 1004, Loss: 0.6531148231557781\n",
            "Epoch: 1005, Loss: 0.6531139060007473\n",
            "Epoch: 1006, Loss: 0.6531129908381001\n",
            "Epoch: 1007, Loss: 0.6531120776618768\n",
            "Epoch: 1008, Loss: 0.6531111664661419\n",
            "Epoch: 1009, Loss: 0.6531102572449827\n",
            "Epoch: 1010, Loss: 0.6531093499925118\n",
            "Epoch: 1011, Loss: 0.653108444702864\n",
            "Epoch: 1012, Loss: 0.6531075413701981\n",
            "Epoch: 1013, Loss: 0.6531066399886963\n",
            "Epoch: 1014, Loss: 0.6531057405525639\n",
            "Epoch: 1015, Loss: 0.653104843056029\n",
            "Epoch: 1016, Loss: 0.6531039474933432\n",
            "Epoch: 1017, Loss: 0.6531030538587805\n",
            "Epoch: 1018, Loss: 0.6531021621466376\n",
            "Epoch: 1019, Loss: 0.653101272351234\n",
            "Epoch: 1020, Loss: 0.6531003844669117\n",
            "Epoch: 1021, Loss: 0.6530994984880348\n",
            "Epoch: 1022, Loss: 0.6530986144089898\n",
            "Epoch: 1023, Loss: 0.6530977322241852\n",
            "Epoch: 1024, Loss: 0.6530968519280516\n",
            "Epoch: 1025, Loss: 0.6530959735150416\n",
            "Epoch: 1026, Loss: 0.6530950969796293\n",
            "Epoch: 1027, Loss: 0.6530942223163108\n",
            "Epoch: 1028, Loss: 0.6530933495196033\n",
            "Epoch: 1029, Loss: 0.6530924785840456\n",
            "Epoch: 1030, Loss: 0.6530916095041981\n",
            "Epoch: 1031, Loss: 0.6530907422746423\n",
            "Epoch: 1032, Loss: 0.6530898768899804\n",
            "Epoch: 1033, Loss: 0.653089013344836\n",
            "Epoch: 1034, Loss: 0.6530881516338536\n",
            "Epoch: 1035, Loss: 0.6530872917516981\n",
            "Epoch: 1036, Loss: 0.6530864336930556\n",
            "Epoch: 1037, Loss: 0.6530855774526321\n",
            "Epoch: 1038, Loss: 0.6530847230251547\n",
            "Epoch: 1039, Loss: 0.6530838704053706\n",
            "Epoch: 1040, Loss: 0.6530830195880469\n",
            "Epoch: 1041, Loss: 0.6530821705679716\n",
            "Epoch: 1042, Loss: 0.6530813233399518\n",
            "Epoch: 1043, Loss: 0.6530804778988155\n",
            "Epoch: 1044, Loss: 0.6530796342394097\n",
            "Epoch: 1045, Loss: 0.6530787923566016\n",
            "Epoch: 1046, Loss: 0.6530779522452781\n",
            "Epoch: 1047, Loss: 0.6530771139003451\n",
            "Epoch: 1048, Loss: 0.6530762773167285\n",
            "Epoch: 1049, Loss: 0.6530754424893734\n",
            "Epoch: 1050, Loss: 0.6530746094132439\n",
            "Epoch: 1051, Loss: 0.6530737780833233\n",
            "Epoch: 1052, Loss: 0.6530729484946144\n",
            "Epoch: 1053, Loss: 0.6530721206421379\n",
            "Epoch: 1054, Loss: 0.6530712945209347\n",
            "Epoch: 1055, Loss: 0.6530704701260636\n",
            "Epoch: 1056, Loss: 0.6530696474526019\n",
            "Epoch: 1057, Loss: 0.653068826495646\n",
            "Epoch: 1058, Loss: 0.6530680072503109\n",
            "Epoch: 1059, Loss: 0.6530671897117292\n",
            "Epoch: 1060, Loss: 0.6530663738750523\n",
            "Epoch: 1061, Loss: 0.65306555973545\n",
            "Epoch: 1062, Loss: 0.6530647472881098\n",
            "Epoch: 1063, Loss: 0.6530639365282372\n",
            "Epoch: 1064, Loss: 0.6530631274510562\n",
            "Epoch: 1065, Loss: 0.6530623200518075\n",
            "Epoch: 1066, Loss: 0.6530615143257511\n",
            "Epoch: 1067, Loss: 0.6530607102681634\n",
            "Epoch: 1068, Loss: 0.6530599078743385\n",
            "Epoch: 1069, Loss: 0.653059107139589\n",
            "Epoch: 1070, Loss: 0.6530583080592438\n",
            "Epoch: 1071, Loss: 0.6530575106286494\n",
            "Epoch: 1072, Loss: 0.6530567148431697\n",
            "Epoch: 1073, Loss: 0.6530559206981857\n",
            "Epoch: 1074, Loss: 0.6530551281890956\n",
            "Epoch: 1075, Loss: 0.6530543373113142\n",
            "Epoch: 1076, Loss: 0.6530535480602735\n",
            "Epoch: 1077, Loss: 0.6530527604314222\n",
            "Epoch: 1078, Loss: 0.6530519744202256\n",
            "Epoch: 1079, Loss: 0.6530511900221657\n",
            "Epoch: 1080, Loss: 0.6530504072327415\n",
            "Epoch: 1081, Loss: 0.653049626047468\n",
            "Epoch: 1082, Loss: 0.6530488464618767\n",
            "Epoch: 1083, Loss: 0.6530480684715152\n",
            "Epoch: 1084, Loss: 0.653047292071948\n",
            "Epoch: 1085, Loss: 0.6530465172587551\n",
            "Epoch: 1086, Loss: 0.6530457440275331\n",
            "Epoch: 1087, Loss: 0.6530449723738943\n",
            "Epoch: 1088, Loss: 0.6530442022934666\n",
            "Epoch: 1089, Loss: 0.6530434337818946\n",
            "Epoch: 1090, Loss: 0.6530426668348381\n",
            "Epoch: 1091, Loss: 0.6530419014479728\n",
            "Epoch: 1092, Loss: 0.6530411376169898\n",
            "Epoch: 1093, Loss: 0.6530403753375961\n",
            "Epoch: 1094, Loss: 0.653039614605514\n",
            "Epoch: 1095, Loss: 0.6530388554164809\n",
            "Epoch: 1096, Loss: 0.6530380977662503\n",
            "Epoch: 1097, Loss: 0.6530373416505898\n",
            "Epoch: 1098, Loss: 0.6530365870652836\n",
            "Epoch: 1099, Loss: 0.6530358340061301\n",
            "Epoch: 1100, Loss: 0.6530350824689427\n",
            "Epoch: 1101, Loss: 0.65303433244955\n",
            "Epoch: 1102, Loss: 0.6530335839437958\n",
            "Epoch: 1103, Loss: 0.6530328369475382\n",
            "Epoch: 1104, Loss: 0.6530320914566504\n",
            "Epoch: 1105, Loss: 0.6530313474670201\n",
            "Epoch: 1106, Loss: 0.6530306049745497\n",
            "Epoch: 1107, Loss: 0.6530298639751564\n",
            "Epoch: 1108, Loss: 0.653029124464771\n",
            "Epoch: 1109, Loss: 0.65302838643934\n",
            "Epoch: 1110, Loss: 0.6530276498948232\n",
            "Epoch: 1111, Loss: 0.6530269148271954\n",
            "Epoch: 1112, Loss: 0.6530261812324449\n",
            "Epoch: 1113, Loss: 0.6530254491065748\n",
            "Epoch: 1114, Loss: 0.653024718445602\n",
            "Epoch: 1115, Loss: 0.6530239892455573\n",
            "Epoch: 1116, Loss: 0.6530232615024857\n",
            "Epoch: 1117, Loss: 0.6530225352124457\n",
            "Epoch: 1118, Loss: 0.6530218103715103\n",
            "Epoch: 1119, Loss: 0.6530210869757654\n",
            "Epoch: 1120, Loss: 0.6530203650213113\n",
            "Epoch: 1121, Loss: 0.6530196445042616\n",
            "Epoch: 1122, Loss: 0.6530189254207436\n",
            "Epoch: 1123, Loss: 0.653018207766898\n",
            "Epoch: 1124, Loss: 0.653017491538879\n",
            "Epoch: 1125, Loss: 0.6530167767328539\n",
            "Epoch: 1126, Loss: 0.6530160633450037\n",
            "Epoch: 1127, Loss: 0.6530153513715228\n",
            "Epoch: 1128, Loss: 0.6530146408086182\n",
            "Epoch: 1129, Loss: 0.6530139316525103\n",
            "Epoch: 1130, Loss: 0.653013223899433\n",
            "Epoch: 1131, Loss: 0.6530125175456327\n",
            "Epoch: 1132, Loss: 0.6530118125873686\n",
            "Epoch: 1133, Loss: 0.6530111090209136\n",
            "Epoch: 1134, Loss: 0.6530104068425526\n",
            "Epoch: 1135, Loss: 0.6530097060485839\n",
            "Epoch: 1136, Loss: 0.6530090066353182\n",
            "Epoch: 1137, Loss: 0.6530083085990785\n",
            "Epoch: 1138, Loss: 0.6530076119362014\n",
            "Epoch: 1139, Loss: 0.6530069166430352\n",
            "Epoch: 1140, Loss: 0.653006222715941\n",
            "Epoch: 1141, Loss: 0.6530055301512923\n",
            "Epoch: 1142, Loss: 0.6530048389454751\n",
            "Epoch: 1143, Loss: 0.6530041490948876\n",
            "Epoch: 1144, Loss: 0.6530034605959402\n",
            "Epoch: 1145, Loss: 0.6530027734450558\n",
            "Epoch: 1146, Loss: 0.653002087638669\n",
            "Epoch: 1147, Loss: 0.6530014031732269\n",
            "Epoch: 1148, Loss: 0.6530007200451888\n",
            "Epoch: 1149, Loss: 0.6530000382510251\n",
            "Epoch: 1150, Loss: 0.6529993577872197\n",
            "Epoch: 1151, Loss: 0.6529986786502668\n",
            "Epoch: 1152, Loss: 0.6529980008366731\n",
            "Epoch: 1153, Loss: 0.6529973243429575\n",
            "Epoch: 1154, Loss: 0.6529966491656504\n",
            "Epoch: 1155, Loss: 0.6529959753012929\n",
            "Epoch: 1156, Loss: 0.6529953027464394\n",
            "Epoch: 1157, Loss: 0.6529946314976545\n",
            "Epoch: 1158, Loss: 0.652993961551515\n",
            "Epoch: 1159, Loss: 0.6529932929046095\n",
            "Epoch: 1160, Loss: 0.652992625553537\n",
            "Epoch: 1161, Loss: 0.6529919594949086\n",
            "Epoch: 1162, Loss: 0.6529912947253468\n",
            "Epoch: 1163, Loss: 0.6529906312414849\n",
            "Epoch: 1164, Loss: 0.6529899690399681\n",
            "Epoch: 1165, Loss: 0.6529893081174521\n",
            "Epoch: 1166, Loss: 0.652988648470604\n",
            "Epoch: 1167, Loss: 0.652987990096102\n",
            "Epoch: 1168, Loss: 0.6529873329906355\n",
            "Epoch: 1169, Loss: 0.6529866771509046\n",
            "Epoch: 1170, Loss: 0.6529860225736205\n",
            "Epoch: 1171, Loss: 0.6529853692555052\n",
            "Epoch: 1172, Loss: 0.6529847171932918\n",
            "Epoch: 1173, Loss: 0.6529840663837237\n",
            "Epoch: 1174, Loss: 0.6529834168235557\n",
            "Epoch: 1175, Loss: 0.6529827685095526\n",
            "Epoch: 1176, Loss: 0.6529821214384904\n",
            "Epoch: 1177, Loss: 0.6529814756071556\n",
            "Epoch: 1178, Loss: 0.6529808310123453\n",
            "Epoch: 1179, Loss: 0.6529801876508665\n",
            "Epoch: 1180, Loss: 0.6529795455195379\n",
            "Epoch: 1181, Loss: 0.6529789046151874\n",
            "Epoch: 1182, Loss: 0.652978264934654\n",
            "Epoch: 1183, Loss: 0.6529776264747871\n",
            "Epoch: 1184, Loss: 0.6529769892324458\n",
            "Epoch: 1185, Loss: 0.6529763532045002\n",
            "Epoch: 1186, Loss: 0.6529757183878301\n",
            "Epoch: 1187, Loss: 0.6529750847793253\n",
            "Epoch: 1188, Loss: 0.6529744523758865\n",
            "Epoch: 1189, Loss: 0.6529738211744237\n",
            "Epoch: 1190, Loss: 0.6529731911718574\n",
            "Epoch: 1191, Loss: 0.6529725623651181\n",
            "Epoch: 1192, Loss: 0.6529719347511457\n",
            "Epoch: 1193, Loss: 0.6529713083268908\n",
            "Epoch: 1194, Loss: 0.6529706830893135\n",
            "Epoch: 1195, Loss: 0.6529700590353837\n",
            "Epoch: 1196, Loss: 0.6529694361620807\n",
            "Epoch: 1197, Loss: 0.6529688144663947\n",
            "Epoch: 1198, Loss: 0.6529681939453242\n",
            "Epoch: 1199, Loss: 0.6529675745958787\n",
            "Epoch: 1200, Loss: 0.6529669564150761\n",
            "Epoch: 1201, Loss: 0.652966339399945\n",
            "Epoch: 1202, Loss: 0.6529657235475225\n",
            "Epoch: 1203, Loss: 0.6529651088548558\n",
            "Epoch: 1204, Loss: 0.6529644953190018\n",
            "Epoch: 1205, Loss: 0.6529638829370262\n",
            "Epoch: 1206, Loss: 0.6529632717060048\n",
            "Epoch: 1207, Loss: 0.6529626616230219\n",
            "Epoch: 1208, Loss: 0.6529620526851717\n",
            "Epoch: 1209, Loss: 0.6529614448895578\n",
            "Epoch: 1210, Loss: 0.6529608382332925\n",
            "Epoch: 1211, Loss: 0.6529602327134978\n",
            "Epoch: 1212, Loss: 0.6529596283273043\n",
            "Epoch: 1213, Loss: 0.6529590250718522\n",
            "Epoch: 1214, Loss: 0.652958422944291\n",
            "Epoch: 1215, Loss: 0.6529578219417782\n",
            "Epoch: 1216, Loss: 0.6529572220614815\n",
            "Epoch: 1217, Loss: 0.652956623300577\n",
            "Epoch: 1218, Loss: 0.6529560256562498\n",
            "Epoch: 1219, Loss: 0.6529554291256936\n",
            "Epoch: 1220, Loss: 0.6529548337061117\n",
            "Epoch: 1221, Loss: 0.6529542393947155\n",
            "Epoch: 1222, Loss: 0.6529536461887258\n",
            "Epoch: 1223, Loss: 0.6529530540853716\n",
            "Epoch: 1224, Loss: 0.6529524630818909\n",
            "Epoch: 1225, Loss: 0.6529518731755304\n",
            "Epoch: 1226, Loss: 0.6529512843635453\n",
            "Epoch: 1227, Loss: 0.6529506966431996\n",
            "Epoch: 1228, Loss: 0.6529501100117658\n",
            "Epoch: 1229, Loss: 0.6529495244665251\n",
            "Epoch: 1230, Loss: 0.6529489400047668\n",
            "Epoch: 1231, Loss: 0.652948356623789\n",
            "Epoch: 1232, Loss: 0.6529477743208985\n",
            "Epoch: 1233, Loss: 0.6529471930934095\n",
            "Epoch: 1234, Loss: 0.6529466129386459\n",
            "Epoch: 1235, Loss: 0.6529460338539392\n",
            "Epoch: 1236, Loss: 0.652945455836629\n",
            "Epoch: 1237, Loss: 0.6529448788840638\n",
            "Epoch: 1238, Loss: 0.6529443029936\n",
            "Epoch: 1239, Loss: 0.652943728162602\n",
            "Epoch: 1240, Loss: 0.652943154388443\n",
            "Epoch: 1241, Loss: 0.6529425816685037\n",
            "Epoch: 1242, Loss: 0.6529420100001733\n",
            "Epoch: 1243, Loss: 0.6529414393808489\n",
            "Epoch: 1244, Loss: 0.6529408698079359\n",
            "Epoch: 1245, Loss: 0.6529403012788471\n",
            "Epoch: 1246, Loss: 0.6529397337910041\n",
            "Epoch: 1247, Loss: 0.6529391673418361\n",
            "Epoch: 1248, Loss: 0.65293860192878\n",
            "Epoch: 1249, Loss: 0.6529380375492807\n",
            "Epoch: 1250, Loss: 0.6529374742007913\n",
            "Epoch: 1251, Loss: 0.6529369118807723\n",
            "Epoch: 1252, Loss: 0.6529363505866924\n",
            "Epoch: 1253, Loss: 0.6529357903160276\n",
            "Epoch: 1254, Loss: 0.6529352310662618\n",
            "Epoch: 1255, Loss: 0.652934672834887\n",
            "Epoch: 1256, Loss: 0.6529341156194024\n",
            "Epoch: 1257, Loss: 0.6529335594173149\n",
            "Epoch: 1258, Loss: 0.6529330042261395\n",
            "Epoch: 1259, Loss: 0.6529324500433981\n",
            "Epoch: 1260, Loss: 0.6529318968666206\n",
            "Epoch: 1261, Loss: 0.6529313446933442\n",
            "Epoch: 1262, Loss: 0.6529307935211138\n",
            "Epoch: 1263, Loss: 0.6529302433474816\n",
            "Epoch: 1264, Loss: 0.6529296941700075\n",
            "Epoch: 1265, Loss: 0.6529291459862587\n",
            "Epoch: 1266, Loss: 0.6529285987938093\n",
            "Epoch: 1267, Loss: 0.6529280525902416\n",
            "Epoch: 1268, Loss: 0.6529275073731446\n",
            "Epoch: 1269, Loss: 0.6529269631401149\n",
            "Epoch: 1270, Loss: 0.6529264198887563\n",
            "Epoch: 1271, Loss: 0.6529258776166798\n",
            "Epoch: 1272, Loss: 0.6529253363215034\n",
            "Epoch: 1273, Loss: 0.652924796000853\n",
            "Epoch: 1274, Loss: 0.652924256652361\n",
            "Epoch: 1275, Loss: 0.652923718273667\n",
            "Epoch: 1276, Loss: 0.6529231808624181\n",
            "Epoch: 1277, Loss: 0.652922644416268\n",
            "Epoch: 1278, Loss: 0.6529221089328776\n",
            "Epoch: 1279, Loss: 0.6529215744099155\n",
            "Epoch: 1280, Loss: 0.6529210408450558\n",
            "Epoch: 1281, Loss: 0.6529205082359811\n",
            "Epoch: 1282, Loss: 0.6529199765803803\n",
            "Epoch: 1283, Loss: 0.6529194458759491\n",
            "Epoch: 1284, Loss: 0.65291891612039\n",
            "Epoch: 1285, Loss: 0.652918387311413\n",
            "Epoch: 1286, Loss: 0.6529178594467346\n",
            "Epoch: 1287, Loss: 0.6529173325240777\n",
            "Epoch: 1288, Loss: 0.6529168065411726\n",
            "Epoch: 1289, Loss: 0.6529162814957562\n",
            "Epoch: 1290, Loss: 0.6529157573855717\n",
            "Epoch: 1291, Loss: 0.6529152342083697\n",
            "Epoch: 1292, Loss: 0.6529147119619071\n",
            "Epoch: 1293, Loss: 0.6529141906439478\n",
            "Epoch: 1294, Loss: 0.6529136702522618\n",
            "Epoch: 1295, Loss: 0.6529131507846259\n",
            "Epoch: 1296, Loss: 0.6529126322388237\n",
            "Epoch: 1297, Loss: 0.6529121146126453\n",
            "Epoch: 1298, Loss: 0.6529115979038873\n",
            "Epoch: 1299, Loss: 0.6529110821103531\n",
            "Epoch: 1300, Loss: 0.6529105672298515\n",
            "Epoch: 1301, Loss: 0.6529100532601995\n",
            "Epoch: 1302, Loss: 0.6529095401992191\n",
            "Epoch: 1303, Loss: 0.6529090280447393\n",
            "Epoch: 1304, Loss: 0.6529085167945956\n",
            "Epoch: 1305, Loss: 0.6529080064466295\n",
            "Epoch: 1306, Loss: 0.6529074969986896\n",
            "Epoch: 1307, Loss: 0.6529069884486294\n",
            "Epoch: 1308, Loss: 0.6529064807943106\n",
            "Epoch: 1309, Loss: 0.6529059740335994\n",
            "Epoch: 1310, Loss: 0.6529054681643697\n",
            "Epoch: 1311, Loss: 0.6529049631845003\n",
            "Epoch: 1312, Loss: 0.6529044590918774\n",
            "Epoch: 1313, Loss: 0.6529039558843928\n",
            "Epoch: 1314, Loss: 0.6529034535599444\n",
            "Epoch: 1315, Loss: 0.6529029521164366\n",
            "Epoch: 1316, Loss: 0.6529024515517794\n",
            "Epoch: 1317, Loss: 0.6529019518638897\n",
            "Epoch: 1318, Loss: 0.6529014530506896\n",
            "Epoch: 1319, Loss: 0.6529009551101078\n",
            "Epoch: 1320, Loss: 0.6529004580400789\n",
            "Epoch: 1321, Loss: 0.6528999618385434\n",
            "Epoch: 1322, Loss: 0.652899466503448\n",
            "Epoch: 1323, Loss: 0.6528989720327453\n",
            "Epoch: 1324, Loss: 0.6528984784243937\n",
            "Epoch: 1325, Loss: 0.6528979856763578\n",
            "Epoch: 1326, Loss: 0.6528974937866078\n",
            "Epoch: 1327, Loss: 0.65289700275312\n",
            "Epoch: 1328, Loss: 0.6528965125738763\n",
            "Epoch: 1329, Loss: 0.6528960232468649\n",
            "Epoch: 1330, Loss: 0.6528955347700794\n",
            "Epoch: 1331, Loss: 0.6528950471415194\n",
            "Epoch: 1332, Loss: 0.6528945603591901\n",
            "Epoch: 1333, Loss: 0.6528940744211027\n",
            "Epoch: 1334, Loss: 0.652893589325274\n",
            "Epoch: 1335, Loss: 0.6528931050697265\n",
            "Epoch: 1336, Loss: 0.6528926216524884\n",
            "Epoch: 1337, Loss: 0.6528921390715939\n",
            "Epoch: 1338, Loss: 0.6528916573250823\n",
            "Epoch: 1339, Loss: 0.6528911764109987\n",
            "Epoch: 1340, Loss: 0.6528906963273942\n",
            "Epoch: 1341, Loss: 0.652890217072325\n",
            "Epoch: 1342, Loss: 0.6528897386438532\n",
            "Epoch: 1343, Loss: 0.6528892610400464\n",
            "Epoch: 1344, Loss: 0.6528887842589775\n",
            "Epoch: 1345, Loss: 0.652888308298725\n",
            "Epoch: 1346, Loss: 0.6528878331573735\n",
            "Epoch: 1347, Loss: 0.6528873588330124\n",
            "Epoch: 1348, Loss: 0.6528868853237363\n",
            "Epoch: 1349, Loss: 0.6528864126276461\n",
            "Epoch: 1350, Loss: 0.6528859407428476\n",
            "Epoch: 1351, Loss: 0.652885469667452\n",
            "Epoch: 1352, Loss: 0.6528849993995759\n",
            "Epoch: 1353, Loss: 0.6528845299373417\n",
            "Epoch: 1354, Loss: 0.6528840612788767\n",
            "Epoch: 1355, Loss: 0.6528835934223133\n",
            "Epoch: 1356, Loss: 0.6528831263657896\n",
            "Epoch: 1357, Loss: 0.6528826601074492\n",
            "Epoch: 1358, Loss: 0.6528821946454405\n",
            "Epoch: 1359, Loss: 0.6528817299779173\n",
            "Epoch: 1360, Loss: 0.6528812661030386\n",
            "Epoch: 1361, Loss: 0.6528808030189689\n",
            "Epoch: 1362, Loss: 0.6528803407238776\n",
            "Epoch: 1363, Loss: 0.6528798792159394\n",
            "Epoch: 1364, Loss: 0.6528794184933339\n",
            "Epoch: 1365, Loss: 0.6528789585542462\n",
            "Epoch: 1366, Loss: 0.6528784993968666\n",
            "Epoch: 1367, Loss: 0.6528780410193897\n",
            "Epoch: 1368, Loss: 0.6528775834200166\n",
            "Epoch: 1369, Loss: 0.6528771265969523\n",
            "Epoch: 1370, Loss: 0.6528766705484069\n",
            "Epoch: 1371, Loss: 0.6528762152725963\n",
            "Epoch: 1372, Loss: 0.6528757607677409\n",
            "Epoch: 1373, Loss: 0.6528753070320661\n",
            "Epoch: 1374, Loss: 0.6528748540638022\n",
            "Epoch: 1375, Loss: 0.652874401861185\n",
            "Epoch: 1376, Loss: 0.6528739504224547\n",
            "Epoch: 1377, Loss: 0.6528734997458564\n",
            "Epoch: 1378, Loss: 0.6528730498296409\n",
            "Epoch: 1379, Loss: 0.652872600672063\n",
            "Epoch: 1380, Loss: 0.6528721522713825\n",
            "Epoch: 1381, Loss: 0.6528717046258647\n",
            "Epoch: 1382, Loss: 0.6528712577337793\n",
            "Epoch: 1383, Loss: 0.6528708115934007\n",
            "Epoch: 1384, Loss: 0.6528703662030083\n",
            "Epoch: 1385, Loss: 0.6528699215608865\n",
            "Epoch: 1386, Loss: 0.6528694776653243\n",
            "Epoch: 1387, Loss: 0.6528690345146153\n",
            "Epoch: 1388, Loss: 0.6528685921070582\n",
            "Epoch: 1389, Loss: 0.6528681504409559\n",
            "Epoch: 1390, Loss: 0.6528677095146168\n",
            "Epoch: 1391, Loss: 0.6528672693263533\n",
            "Epoch: 1392, Loss: 0.652866829874483\n",
            "Epoch: 1393, Loss: 0.6528663911573278\n",
            "Epoch: 1394, Loss: 0.6528659531732145\n",
            "Epoch: 1395, Loss: 0.6528655159204743\n",
            "Epoch: 1396, Loss: 0.6528650793974433\n",
            "Epoch: 1397, Loss: 0.652864643602462\n",
            "Epoch: 1398, Loss: 0.6528642085338754\n",
            "Epoch: 1399, Loss: 0.6528637741900337\n",
            "Epoch: 1400, Loss: 0.652863340569291\n",
            "Epoch: 1401, Loss: 0.6528629076700061\n",
            "Epoch: 1402, Loss: 0.6528624754905427\n",
            "Epoch: 1403, Loss: 0.6528620440292684\n",
            "Epoch: 1404, Loss: 0.6528616132845557\n",
            "Epoch: 1405, Loss: 0.6528611832547817\n",
            "Epoch: 1406, Loss: 0.6528607539383277\n",
            "Epoch: 1407, Loss: 0.6528603253335794\n",
            "Epoch: 1408, Loss: 0.6528598974389275\n",
            "Epoch: 1409, Loss: 0.6528594702527662\n",
            "Epoch: 1410, Loss: 0.652859043773495\n",
            "Epoch: 1411, Loss: 0.6528586179995175\n",
            "Epoch: 1412, Loss: 0.6528581929292414\n",
            "Epoch: 1413, Loss: 0.6528577685610791\n",
            "Epoch: 1414, Loss: 0.6528573448934476\n",
            "Epoch: 1415, Loss: 0.6528569219247673\n",
            "Epoch: 1416, Loss: 0.6528564996534639\n",
            "Epoch: 1417, Loss: 0.652856078077967\n",
            "Epoch: 1418, Loss: 0.6528556571967106\n",
            "Epoch: 1419, Loss: 0.6528552370081329\n",
            "Epoch: 1420, Loss: 0.6528548175106762\n",
            "Epoch: 1421, Loss: 0.6528543987027873\n",
            "Epoch: 1422, Loss: 0.6528539805829175\n",
            "Epoch: 1423, Loss: 0.6528535631495219\n",
            "Epoch: 1424, Loss: 0.65285314640106\n",
            "Epoch: 1425, Loss: 0.6528527303359954\n",
            "Epoch: 1426, Loss: 0.6528523149527956\n",
            "Epoch: 1427, Loss: 0.6528519002499332\n",
            "Epoch: 1428, Loss: 0.6528514862258841\n",
            "Epoch: 1429, Loss: 0.6528510728791286\n",
            "Epoch: 1430, Loss: 0.6528506602081511\n",
            "Epoch: 1431, Loss: 0.6528502482114404\n",
            "Epoch: 1432, Loss: 0.6528498368874889\n",
            "Epoch: 1433, Loss: 0.6528494262347936\n",
            "Epoch: 1434, Loss: 0.6528490162518553\n",
            "Epoch: 1435, Loss: 0.6528486069371789\n",
            "Epoch: 1436, Loss: 0.6528481982892734\n",
            "Epoch: 1437, Loss: 0.6528477903066519\n",
            "Epoch: 1438, Loss: 0.6528473829878311\n",
            "Epoch: 1439, Loss: 0.6528469763313324\n",
            "Epoch: 1440, Loss: 0.6528465703356807\n",
            "Epoch: 1441, Loss: 0.6528461649994053\n",
            "Epoch: 1442, Loss: 0.652845760321039\n",
            "Epoch: 1443, Loss: 0.6528453562991187\n",
            "Epoch: 1444, Loss: 0.6528449529321855\n",
            "Epoch: 1445, Loss: 0.6528445502187842\n",
            "Epoch: 1446, Loss: 0.6528441481574637\n",
            "Epoch: 1447, Loss: 0.6528437467467765\n",
            "Epoch: 1448, Loss: 0.6528433459852795\n",
            "Epoch: 1449, Loss: 0.652842945871533\n",
            "Epoch: 1450, Loss: 0.6528425464041014\n",
            "Epoch: 1451, Loss: 0.6528421475815528\n",
            "Epoch: 1452, Loss: 0.6528417494024595\n",
            "Epoch: 1453, Loss: 0.6528413518653975\n",
            "Epoch: 1454, Loss: 0.6528409549689463\n",
            "Epoch: 1455, Loss: 0.6528405587116893\n",
            "Epoch: 1456, Loss: 0.6528401630922145\n",
            "Epoch: 1457, Loss: 0.6528397681091124\n",
            "Epoch: 1458, Loss: 0.6528393737609782\n",
            "Epoch: 1459, Loss: 0.6528389800464104\n",
            "Epoch: 1460, Loss: 0.6528385869640119\n",
            "Epoch: 1461, Loss: 0.6528381945123881\n",
            "Epoch: 1462, Loss: 0.6528378026901497\n",
            "Epoch: 1463, Loss: 0.6528374114959098\n",
            "Epoch: 1464, Loss: 0.6528370209282858\n",
            "Epoch: 1465, Loss: 0.6528366309858991\n",
            "Epoch: 1466, Loss: 0.6528362416673739\n",
            "Epoch: 1467, Loss: 0.6528358529713387\n",
            "Epoch: 1468, Loss: 0.6528354648964257\n",
            "Epoch: 1469, Loss: 0.6528350774412706\n",
            "Epoch: 1470, Loss: 0.6528346906045124\n",
            "Epoch: 1471, Loss: 0.6528343043847944\n",
            "Epoch: 1472, Loss: 0.6528339187807628\n",
            "Epoch: 1473, Loss: 0.6528335337910679\n",
            "Epoch: 1474, Loss: 0.6528331494143634\n",
            "Epoch: 1475, Loss: 0.6528327656493067\n",
            "Epoch: 1476, Loss: 0.6528323824945588\n",
            "Epoch: 1477, Loss: 0.6528319999487837\n",
            "Epoch: 1478, Loss: 0.6528316180106498\n",
            "Epoch: 1479, Loss: 0.6528312366788283\n",
            "Epoch: 1480, Loss: 0.6528308559519945\n",
            "Epoch: 1481, Loss: 0.6528304758288266\n",
            "Epoch: 1482, Loss: 0.652830096308007\n",
            "Epoch: 1483, Loss: 0.6528297173882212\n",
            "Epoch: 1484, Loss: 0.6528293390681575\n",
            "Epoch: 1485, Loss: 0.6528289613465098\n",
            "Epoch: 1486, Loss: 0.6528285842219727\n",
            "Epoch: 1487, Loss: 0.6528282076932462\n",
            "Epoch: 1488, Loss: 0.652827831759033\n",
            "Epoch: 1489, Loss: 0.6528274564180394\n",
            "Epoch: 1490, Loss: 0.6528270816689749\n",
            "Epoch: 1491, Loss: 0.6528267075105527\n",
            "Epoch: 1492, Loss: 0.652826333941489\n",
            "Epoch: 1493, Loss: 0.6528259609605039\n",
            "Epoch: 1494, Loss: 0.6528255885663207\n",
            "Epoch: 1495, Loss: 0.6528252167576656\n",
            "Epoch: 1496, Loss: 0.6528248455332688\n",
            "Epoch: 1497, Loss: 0.6528244748918632\n",
            "Epoch: 1498, Loss: 0.6528241048321857\n",
            "Epoch: 1499, Loss: 0.6528237353529762\n",
            "Epoch: 1500, Loss: 0.6528233664529778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S1TlALgDbin",
        "outputId": "91d42881-8b3d-4761-8178-744730906e89"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5835], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "mWpsbG6GDe8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred = (y_pred > 0.9).float()\n",
        "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
        "  print(f'Accuracy: {accuracy.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A69_ltY3DeSR",
        "outputId": "0c21a7cc-120d-4bd7-93c3-8ffb456bcbe0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5701754093170166\n"
          ]
        }
      ]
    }
  ]
}